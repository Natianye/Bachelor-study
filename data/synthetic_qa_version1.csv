QA_id,chunk_id,chunk_name,Powerpoint,content,Human_Questions,Human_Answers,synthetic_question,synthetic_answer
1,1,contributing_link_chunks_chunk_10,1,"# Contributing to BayBE
## Writing classes
### Method overrides

When overriding methods in subclasses, decorate them with `@typing_extensions.override`
to make the relationship explicit:

```python
from typing_extensions import override

class Parent:

   def le_method():
      """"""The method of the parent class.""""""
      ...

class Child:

   @override
   def le_method():
      """"""Overridden method of the child class.""""""
      ...
```

Using the decorator provides a type-safe approach for defining inheritance structures
that eliminates two potential sources of unintended class design:

* An intended override is does not occur because the method names differ between
  the parent and child classes (e.g. if the parent method is renamed)
* An unintended override occurs because a method name that exists in the parent class
  is used in the child class by mistake.
  In both cases, `mypy` will complain and force you to fix the problem.",Mypy does not accept my†definition of a function for a child class. What went wrong?†,    @override is missing,What decorator should be used when overriding methods in subclasses for explicit relationship?,`@typing_extensions.override`
2,2,contributing_link_chunks_chunk_2,Tia,"# Contributing to BayBE

**All contributions to BayBE are welcome!**

... no matter if bug fixes, new features, or just typo corrections.

To shorten the overall development and review process, this page contains are a
few sections that can make your life easier.

## General Workflow

To implement your contributions in a local development environment,
we recommend the following workflow:

1. Clone a [fork](https://github.com/emdgroup/BayBE/fork) of the repository to
   your local machine.
2. Create and activate a virtual python environment using one of the supported
   python versions.
3. Change into the root folder of the cloned repository and install an editable version
   including all development dependencies:
   ```console
   pip install -e '.[dev]'
   ```
4. Run our tests to verify everything works as expected:
   ```console
   pytest
   ```
5. Install our [pre-commit](https://pre-commit.com/) hooks:
   ```console
   pre-commit install
   ```
6. Create a new branch for your contribution:
   ```console
   git checkout -b <your_branch_name>
   ```
7. **Implement your changes.**
8. Optional but recommended to prevent complaints from our CI pipeline:
   **Test your code.**

   There are several test environments you can run via `tox`, each corresponding to a
   [developer tool]() in a certain Python version.
   You can retrieve all available environments via `tox list`.
   For more information, see our [README about tests](https://github.com/emdgroup/baybe/blob/main/tests/README.md).

   For instance, running all code tests in Python 3.12 can be achieved via:
   ```console
   tox -e fulltest-py312
   ```

   Other tox tests that are useful to verify your work locally are `tox -e lint-py312`,
   `tox -e mypy-py312` and `tox -e coretest-py312`.

   If you want to challenge your machine, you can run all checks in all Python versions
   in parallel via:
   ```console
   tox -p
   ```

   This can be considered the ultimate one-stop check to make sure your code is ready
   for merge.
9. Push the updated branch back to your fork:
   ```console
   git push origin
   ```
10. Open a pull request via Github√¢¬Ä¬ôs web page.",Can I make changes to improve the BayBE repo?,"# Contributing to BayBE

**All contributions to BayBE are welcome!**

... no matter if bug fixes, new features, or just typo corrections.

To shorten the overall development and review process, this page contains are a
few sections that can make your life easier.

## General Workflow

To implement your contributions in a local development environment,
we recommend the following workflow:

1. Clone a [fork](https://github.com/emdgroup/BayBE/fork) of the repository to
   your local machine.
2. Create and activate a virtual python environment using one of the supported
   python versions.
3. Change into the root folder of the cloned repository and install an editable version
   including all development dependencies:
   ```console
   pip install -e '.[dev]'
   ```
4. Run our tests to verify everything works as expected:
   ```console
   pytest
   ```
5. Install our [pre-commit](https://pre-commit.com/) hooks:
   ```console
   pre-commit install
   ```
6. Create a new branch for your contribution:
   ```console
   git checkout -b <your_branch_name>
   ```
7. **Implement your changes.**
8. Optional but recommended to prevent complaints from our CI pipeline:
   **Test your code.**

   There are several test environments you can run via `tox`, each corresponding to a
   [developer tool]() in a certain Python version.
   You can retrieve all available environments via `tox list`.
   For more information, see our [README about tests](https://github.com/emdgroup/baybe/blob/main/tests/README.md).

   For instance, running all code tests in Python 3.12 can be achieved via:
   ```console
   tox -e fulltest-py312
   ```

   Other tox tests that are useful to verify your work locally are `tox -e lint-py312`,
   `tox -e mypy-py312` and `tox -e coretest-py312`.

   If you want to challenge your machine, you can run all checks in all Python versions
   in parallel via:
   ```console
   tox -p
   ```

   This can be considered the ultimate one-stop check to make sure your code is ready
   for merge.
9. Push the updated branch back to your fork:
   ```console
   git push origin
   ```
10. Open a pull request via Github√¢¬Ä¬ôs web page.",What command is used to install an editable version of the BayBE repository including all development dependencies?,`pip install -e '.[dev]'`
3,3,contributing_link_chunks_chunk_3,2,"# Contributing to BayBE
## Synchronizing Pull Requests

A common situation encountered when submitting a pull request (PR) is that the upstream
branch has evolved since the moment your PR branch was created, and a synchronization
is needed in order to prepare your branch for a merge (e.g., to remove existing
conflicts).

Because we care about our Git history and would like to keep it clean and
easy to follow, we generally recommend **rebasing** your branch onto the latest
upstream commit in such situations, especially if your changes are orthogonal to what
has happened on the remote branch in the meantime. Compared to merging, this has the
advantage of keeping the history of your commits (and thus of the entire repository)
linear, and your own PR free of changes that happened remotely, which also
greatly simplifies the review process (e.g., it produces simpler diffs).

That said, the above is only a recommendation and by no means a requirement. However,
depending on the complexity of your PR commit history, we reserve the right to merge
your branch using a squash-rebase as a last resort to keep our history clean.
By following the guideline above, this step can be easily avoided in most cases.

<a id=""developer-tools""></a>",How should I prepare my†pull request?,,What is the recommended method for synchronizing a pull request branch with the upstream branch?,Rebasing.
4,4,contributing_link_chunks_chunk_4,Tia,"# Contributing to BayBE
## Developer Tools

In order to maintain a high code quality, we use a variety of code developer tools.
When following the above described workflow, [pre-commit](https://pre-commit.com/)
will automatically trigger (most) necessary checks during your development process.
In any case, these checks are also conducted in our CI pipeline, which must pass
before your pull request is considered ready for review.
If you have questions or problems, simply ask for advice.

| Tool                                                                                            | Purpose                                   |
|-------------------------------------------------------------------------------------------------|-------------------------------------------|
| [ruff](https://docs.astral.sh/ruff/)                                                            | code linting and formatting               |
| [mypy](https://mypy.readthedocs.io/)                                                            | static type checking                      |
| [pydocstyle](http://www.pydocstyle.org/)   <br/> [pydoclint](https://github.com/jsh9/pydoclint) | analyzing docstrings                      |
| [typos](https://github.com/crate-ci/typos)                                                      | basic spell checking                      |
| [pytest](https://docs.pytest.org/)                                                              | testing                                   |
| [pytest-cov](https://pytest-cov.readthedocs.io/)                                                | measuring test coverage                   |
| [sphinx](https://www.sphinx-doc.org/)                                                           | generating our documentation              |
| [pip-audit](https://github.com/pypa/pip-audit)                                                  | detecting vulnerabilities in dependencies |
| [tox](https://tox.wiki/)                                                                        | orchestrating all the above               |

Executing a specific one of these tools is easiest by using the corresponding
[tox](https://tox.wiki/) environment,

```console
tox -e <env>
```

where `<env>` is any of the environment names found via `tox list`.

<a id=""code-design""></a>",Do I have to install sphinx seperately?,"No. If you follow the described contribution workflow, pre-commit will automatically trigger sphinx. Or you can Execute it  a specific one by using 
tox -e  sphinx",What tool is used for static type checking in the BayBE developer tools?,mypy
5,5,contributing_link_chunks_chunk_5,3,"# Contributing to BayBE
## Code Design

When reading BayBE√¢¬Ä¬ôs code, you will notice certain re-occurring design patterns.
These patterns are by no means enforced, but following them can streamline your
own development process:

* We build most our classes with [attrs](https://www.attrs.org/), which is useful
  for lean class design and attribute validation.
* Our (de-)serialization machinery is built upon [cattrs](https://catt.rs/), separating
  object serialization from class design.
* The modular nature of BayBE√¢¬Ä¬ôs components is reflected in our test suite through
  the use of [hypothesis](https://hypothesis.readthedocs.io/) property tests.",What are the attrs and cattrs libraries used for?,Attrs is used for class desing and attribute validation while cattrs is being used for object (de-)serialization.,What library is used for lean class design and attribute validation in BayBE?,attrs
6,6,contributing_link_chunks_chunk_6,5,"# Contributing to BayBE
## Extending BayBE√¢¬Ä¬ôs Functionality

For most parts, BayBE√¢¬Ä¬ôs code and functional components are organized into different
subpackages.
When extending its functionality (for instance, by adding new component subclasses),
make sure that the newly written code is well integrated into the existing package and
module hierarchy.
In particular, public functionality should be imported into the appropriate high-level
namespaces for easier user import. For an example, see our
[parameter namespace](https://github.com/emdgroup/baybe/blob/main/baybe/parameters/__init__.py).",What are supported parameter types in baybe and what are their names?,,How should public functionality be organized when extending BayBE's functionality?,Public functionality should be imported into the appropriate high-level namespaces for easier user import.
7,7,contributing_link_chunks_chunk_7,6,"# Contributing to BayBE
## Writing Docstrings

Our docstrings generally follow the
[Google Python Style Guide](https://google.github.io/styleguide/pyguide.html).
Basic style and consistency checks are automatically performed via
[pre-commit](https://pre-commit.com/) during development and in our CI pipeline.

Apart from that, we generally recommend adhering to the following guideline:

- Each function should have a docstring containing:
  * a short one-line summary at the top,
  * an optional extended summary or description below and
  * all relevant sections (`Args`, `Raises`, ...).
- Use type hints (for variables/constants, attributes, function/method signatures, ...).
  Avoid repeating type hints in docstrings.
- When referencing objects (classes, functions, ...),
  use `:<key>:`path.to.function` ` where `<key>` is to be replaced with the
  respective [role](https://www.sphinx-doc.org/en/master/usage/domains/python.html#cross-referencing-python-objects)
  (`class`, `func`, ...)
- Use double backticks for literals like in ```MyString```.",,,What style guide do the docstrings generally follow for BayBE?,Google Python Style Guide
8,8,contributing_link_chunks_chunk_9,9,"# Contributing to BayBE
## Writing classes
### Conventions for `attrs` classes

- Place attribute docstrings below the attribute declaration, not in the class
  docstring.
  Separate different attributes using a blank line.
  For example:
  ```python
  @define
  class Cookies:
    """"""A delicious recipe for chocolate-banana cookies.""""""

    chocolate: float
    """"""Chocolate is naturally measured in terms of floats.""""""

    bananas: int
    """"""For bananas, we use integers, of course.""""""
  ```
- Unless another more specific name is suitable, use our default naming convention for
  `attrs` defaults and validators:
  ```python
  @my_attribute.default
  def _default_my_attribute(self): ...

  @my_attribute.validator
  def _validate_my_attribute(self, attribute, value): ...
  ```

  A one-line docstring suffices for these methods, but they should have a `Raises:`
  section if applicable. Linter warnings regarding missing attribute docstrings can be
  silenced using `# noqa: DOC101, DOC103`.",What is the docstring convention in BayBE?,,Where should attribute docstrings be placed in `attrs` classes?,"Below the attribute declaration, not in the class docstring."
9,9,faq_chunks_chunk_2,,"# FAQ
### Do I need to create a campaign to get recommendations?

No, creating a campaign is not mandatory.
BayBE offers two entry points for generating recommendations:

* a stateful [`Campaign.recommend`]() method and
* a stateless [`RecommenderProtocol.recommend`]() method.

",Do I need to create a campaign to get recommendations?,"No, creating a campaign is not mandatory.
BayBE offers two entry points for generating recommendations:

* a stateful [`Campaign.recommend`]() method and
* a stateless [`RecommenderProtocol.recommend`]() method.
",Is it necessary to create a campaign to receive recommendations?,"No, creating a campaign is not mandatory."
10,10,faq_chunks_chunk_3,,"# FAQ
### BayBE recommends A but experimentalists do B. What now?

Don√¢¬Ä¬ôt panic and grab your towel. Recommendations from BayBE are just ... well,
√¢¬Ä¬úrecommendations√¢¬Ä¬ù. The measurements you feed back to BayBE need not to be related to
the original recommendation in any way. In fact, requesting recommendations and adding
data are two separate actions, and there is no formal requirement to perform these
actions in any particular order nor to √¢¬Ä¬úrespond√¢¬Ä¬ù to recommendations in any form.

Note, however, that subsequent recommendations **may** be affected by earlier steps in
your campaign, depending on your settings for the
`allow_recommending_already_measured` and
`allow_recommending_already_recommended` flags.",BayBE recommends A but experimentalists do B. What now?,"
Don√¢¬Ä¬ôt panic and grab your towel. Recommendations from BayBE are just ... well,
√¢¬Ä¬úrecommendations√¢¬Ä¬ù. The measurements you feed back to BayBE need not to be related to
the original recommendation in any way. In fact, requesting recommendations and adding
data are two separate actions, and there is no formal requirement to perform these
actions in any particular order nor to √¢¬Ä¬úrespond√¢¬Ä¬ù to recommendations in any form.

Note, however, that subsequent recommendations **may** be affected by earlier steps in
your campaign, depending on your settings for the
`allow_recommending_already_measured` and
`allow_recommending_already_recommended` flags.",What should you do if BayBE recommends A but you want to do B?,Don't panic; recommendations from BayBE are just recommendations and do not have to be followed.
11,11,index_chunks_chunk_10,2,"# BayBE √¢¬Ä¬î A Bayesian Back End for Design of Experiments
## √∞¬ü¬í¬ª Installation
### From Package Index

The easiest way to install BayBE is via PyPI:

```bash
pip install baybe
```

A certain released version of the package can be installed by specifying the
corresponding version tag in the form `baybe==x.y.z`.",How to install BayBE?,,How can I install BayBE?,You can install BayBE via PyPI using the command `pip install baybe`.
12,12,index_chunks_chunk_11,6,"# BayBE √¢¬Ä¬î A Bayesian Back End for Design of Experiments
## √∞¬ü¬í¬ª Installation
### From GitHub

If you need finer control and would like to install a specific commit that has not been
released under a certain version tag, you can do so by installing BayBE directly from
GitHub via git and specifying the corresponding
[git ref](https://pip.pypa.io/en/stable/topics/vcs-support/#git).

For instance, to install the latest commit of the main branch, run:

```bash
pip install git+https://github.com/emdgroup/baybe.git@main
```",,,How can I install the latest commit of the main branch of BayBE from GitHub?,Run the command `pip install git+https://github.com/emdgroup/baybe.git@main`.
13,13,index_chunks_chunk_12,8,"# BayBE √¢¬Ä¬î A Bayesian Back End for Design of Experiments
## √∞¬ü¬í¬ª Installation
### From Local Clone

Alternatively, you can install the package from your own local copy.
First, clone the repository, navigate to the repository root folder, check out the
desired commit, and run:

```bash
pip install .
```

A developer would typically also install the package in editable mode (√¢¬Ä¬ò-e√¢¬Ä¬ô),
which ensures that changes to the code do not require a reinstallation.

```bash
pip install -e .
```

If you need to add additional dependencies, make sure to use the correct syntax
including `''`:

```bash
pip install -e '.[dev]'
```",,,How do you install the BayBE package in editable mode?,Run the command `pip install -e .`.
14,14,index_chunks_chunk_13,9,"# BayBE √¢¬Ä¬î A Bayesian Back End for Design of Experiments
## √∞¬ü¬í¬ª Installation
### Optional Dependencies

There are several dependency groups that can be selected during pip installation, like

```bash
pip install 'baybe[test,lint]' # will install baybe with additional dependency groups `test` and `lint`
```

To get the most out of `baybe`, we recommend to install at least

```bash
pip install 'baybe[chem,simulation]'
```

The available groups are:

- `extras`: Installs all dependencies required for optional features.
- `benchmarking`: Required for running the benchmarking module.
- `chem`: Cheminformatics utilities (e.g. for the `SubstanceParameter`).
- `docs`: Required for creating the documentation.
- `examples`: Required for running the examples/streamlit.
- `lint`: Required for linting and formatting.
- `mypy`: Required for static type checking.
- `onnx`: Required for using custom surrogate models in [ONNX format](https://onnx.ai).
- `polars`: Required for optimized search space construction via [Polars](https://docs.pola.rs/).
- `insights`: Required for built-in model and campaign analysis (e.g. using [SHAP](https://shap.readthedocs.io/)).
- `simulation`: Enabling the [simulation](https://emdgroup.github.io/baybe/stable/_autosummary/baybe.simulation.html) module.
- `test`: Required for running the tests.
- `dev`: All of the above plus dev tools. For code contributors.",How do I install BayBE? Walk me through the installation process for BayBE.,,What command installs the `baybe` package with the optional dependencies for cheminformatics and simulation?,"`pip install 'baybe[chem,simulation]'`"
15,15,index_chunks_chunk_14,10,"# BayBE √¢¬Ä¬î A Bayesian Back End for Design of Experiments
## √∞¬ü¬ì¬° Telemetry

BayBE collects anonymous usage statistics **only** for employees of Merck KGaA,
Darmstadt, Germany and/or its affiliates. The recording of metrics is turned off for
all other users and is impossible due to a VPN block. In any case, the usage statistics
do **not** involve logging of recorded measurements, targets/parameters or their names
or any project information that would allow for reconstruction of details. The user and
host machine names are anonymized with via truncated hashing.

- You can verify the above statements by studying the open-source code in the
  `telemetry` module.
- You can always deactivate all telemetry by setting the environment variable
  `BAYBE_TELEMETRY_ENABLED` to `false` or `off`. For details please consult
  [this page](https://emdgroup.github.io/baybe/stable/userguide/envvars.html#telemetry).
- If you want to be absolutely sure, you can uninstall internet related packages such
  as `opentelemetry*` or its secondary dependencies from the environment. Due to the
  inability of specifying opt-out dependencies, these are installed by default, but the
  package works without them.","Does BayBE collect usage statistics?
","BayBE only collects usage statistics for employees of Merck KGaA, Darmstadt, Germany.",Who does BayBE collect anonymous usage statistics from?,"Employees of Merck KGaA, Darmstadt, Germany and/or its affiliates."
16,16,index_chunks_chunk_2,3,"# BayBE √¢¬Ä¬î A Bayesian Back End for Design of Experiments

The **Bay**esian **B**ack **E**nd (**BayBE**) is a general-purpose toolbox for Bayesian Design
of Experiments, focusing on additions that enable real-world experimental campaigns.

## √∞¬ü¬î¬ã Batteries Included

Besides its core functionality to perform a typical recommend-measure loop, BayBE
offers a range of √¢¬ú¬®**built√¢¬Ä¬ëin√Ç¬†features**√¢¬ú¬® crucial for real-world use cases.
The following provides a non-comprehensive overview:

- √∞¬ü¬õ¬†√Ø¬∏¬è Custom parameter encodings: Improve your campaign with domain knowledge
- √∞¬ü¬ß¬™ Built-in chemical encodings: Improve your campaign with chemical knowledge
- √∞¬ü¬é¬Ø Numerical and binary targets with min, max and match objectives
- √¢¬ö¬ñ√Ø¬∏¬è  Multi-target support via Pareto optimization and desirability scalarization
- √∞¬ü¬î¬ç Insights: Easily analyze feature importance and model behavior
- √∞¬ü¬é¬≠ Hybrid (mixed continuous and discrete) spaces
- √∞¬ü¬ö¬Ä Transfer learning: Mix data from multiple campaigns and accelerate optimization
- √∞¬ü¬é¬∞ Bandit models: Efficiently find the best among many options in noisy environments (e.g. A/B Testing)
- √∞¬ü¬î¬¢ Cardinality constraints: Control the number of active factors in your design
- √∞¬ü¬å¬é Distributed workflows: Run campaigns asynchronously with pending experiments and partial measurements
- √∞¬ü¬é¬ì Active learning: Perform smart data acquisition campaigns
- √¢¬ö¬ô√Ø¬∏¬è Custom surrogate models: Enhance your predictions through mechanistic understanding
- √∞¬ü¬ì¬à Comprehensive backtest, simulation and imputation utilities: Benchmark and find your best settings
- √∞¬ü¬ì¬ù Fully typed and hypothesis-tested: Robust code base
- √∞¬ü¬î¬Ñ All objects are fully (de-)serializable: Useful for storing results in databases or use in wrappers like APIs",Which kinds of targets are supported by BayBE?,"BayBE supports numerical and binary targets with min, max, and match objectives as well as multi-target optimization via a Pareto approach or desirability scalarization.",What is BayBE primarily used for?,Bayesian Design of Experiments.
17,17,index_chunks_chunk_4,1,"# BayBE √¢¬Ä¬î A Bayesian Back End for Design of Experiments
## √¢¬ö¬° Quick Start
Let us consider a simple experiment where we control three parameters and want to
maximize a single target called `Yield`.

First, install BayBE into your Python environment:

```bash
pip install baybe
```
### Defining the Optimization Objective

In BayBE√¢¬Ä¬ôs language, the `Yield` can be represented as a `NumericalTarget`,
which we wrap into a `SingleTargetObjective`:

```python
from baybe.targets import NumericalTarget
from baybe.objectives import SingleTargetObjective

target = NumericalTarget(
    name=""Yield"",
    mode=""MAX"",
)
objective = SingleTargetObjective(target=target)
```

In cases where we are confronted with multiple (potentially conflicting) targets,
the `ParetoObjective` or `DesirabilityObjective` can be used instead.
These allow to define additional settings, such as how the targets should be balanced.",Give me a code example on how to get started with BayBE,"```bash 
pip install†baybe†
``` 
### Defining the OptimizationObjective 
In†BayBE†language, the `Yield`can be represented as a`NumericalTarget`, 
which we wrap into a`SingleTargetObjective`: 
```python 
from†baybe.targets†import†NumericalTarget†
from†baybe.objectives†import†SingleTargetObjective†

target =†NumericalTarget( 
name=""Yield"", 
mode=""MAX"", 
) 
objective=†SingleTargetObjective(target=target) 
```
And addtionaly setup of campaign and syntax for recommendations",How do you install BayBE in a Python environment?,You can install BayBE by running the command `pip install baybe`.
18,18,index_chunks_chunk_5,Tia,"# BayBE √¢¬Ä¬î A Bayesian Back End for Design of Experiments
## √¢¬ö¬° Quick Start
### Defining the Search Space

Next, we inform BayBE about the available √¢¬Ä¬úcontrol knobs√¢¬Ä¬ù, that is, the underlying
system parameters we can tune to optimize our targets. This also involves specifying
their values/ranges and other parameter-specific details.

For our example, we assume that we can control three parameters √¢¬Ä¬ì `Granularity`,
`Pressure[bar]`, and `Solvent` √¢¬Ä¬ì as follows:

```python
from baybe.parameters import (
    CategoricalParameter,
    NumericalDiscreteParameter,
    SubstanceParameter,
)

parameters = [
    CategoricalParameter(
        name=""Granularity"",
        values=[""coarse"", ""medium"", ""fine""],
        encoding=""OHE"",  # one-hot encoding of categories
    ),
    NumericalDiscreteParameter(
        name=""Pressure[bar]"",
        values=[1, 5, 10],
        tolerance=0.2,  # allows experimental inaccuracies up to 0.2 when reading values
    ),
    SubstanceParameter(
        name=""Solvent"",
        data={
            ""Solvent A"": ""COC"",
            ""Solvent B"": ""CCC"",  # label-SMILES pairs
            ""Solvent C"": ""O"",
            ""Solvent D"": ""CS(=O)C"",
        },
        encoding=""MORDRED"",  # chemical encoding via scikit-fingerprints
    ),
]
```

For more parameter types and their details, see the
[parameters section](https://emdgroup.github.io/baybe/stable/userguide/parameters.html)
of the user guide.

Additionally, we can define a set of constraints to further specify allowed ranges and
relationships between our parameters. Details can be found in the
[constraints section](https://emdgroup.github.io/baybe/stable/userguide/constraints.html) of the user guide.
In this example, we assume no further constraints.

With the parameter definitions at hand, we can now create our
`SearchSpace` based on the Cartesian product of all possible parameter values:

```python
from baybe.searchspace import SearchSpace

searchspace = SearchSpace.from_product(parameters)
```

See the [search spaces section](https://emdgroup.github.io/baybe/stable/userguide/searchspace.html)
of our user guide for more information on the structure of search spaces
and alternative ways of construction.",how to inform BayBE about the parameters we can tune to optimize our targets?,"This also involves specifying
their values/ranges and other parameter-specific details.

For our example, we assume that we can control three parameters √¢¬Ä¬ì `Granularity`,
`Pressure[bar]`, and `Solvent` √¢¬Ä¬ì as follows:

```python
from baybe.parameters import (
    CategoricalParameter,
    NumericalDiscreteParameter,
    SubstanceParameter,
)

parameters = [
    CategoricalParameter(
        name=""Granularity"",
        values=[""coarse"", ""medium"", ""fine""],
        encoding=""OHE"",  # one-hot encoding of categories
    ),
    NumericalDiscreteParameter(
        name=""Pressure[bar]"",
        values=[1, 5, 10],
        tolerance=0.2,  # allows experimental inaccuracies up to 0.2 when reading values
    ),
    SubstanceParameter(
        name=""Solvent"",
        data={
            ""Solvent A"": ""COC"",
            ""Solvent B"": ""CCC"",  # label-SMILES pairs
            ""Solvent C"": ""O"",
            ""Solvent D"": ""CS(=O)C"",
        },
        encoding=""MORDRED"",  # chemical encoding via scikit-fingerprints
    ),
]
```

For more parameter types and their details, see the
[parameters section](https://emdgroup.github.io/baybe/stable/userguide/parameters.html)
of the user guide.

Additionally, we can define a set of constraints to further specify allowed ranges and
relationships between our parameters. Details can be found in the
[constraints section](https://emdgroup.github.io/baybe/stable/userguide/constraints.html) of the user guide.
In this example, we assume no further constraints.

With the parameter definitions at hand, we can now create our
`SearchSpace` based on the Cartesian product of all possible parameter values:

```python
from baybe.searchspace import SearchSpace

searchspace = SearchSpace.from_product(parameters)
```
",What three parameters can be controlled in the BayBE design of experiments?,"Granularity, Pressure[bar], and Solvent."
19,19,index_chunks_chunk_6,5,"# BayBE √¢¬Ä¬î A Bayesian Back End for Design of Experiments
## √¢¬ö¬° Quick Start
### Optional: Defining the Optimization Strategy

As an optional step, we can specify details on how the optimization should be
conducted. If omitted, BayBE will choose a default setting.

For our example, we combine two recommenders via a so-called meta recommender named
`TwoPhaseMetaRecommender`:

1. In cases where no measurements have been made prior to the interaction with BayBE,
   a selection via `initial_recommender` is used.
2. As soon as the first measurements are available, we switch to `recommender`.

For more details on the different recommenders, their underlying algorithmic
details, and their configuration settings, see the
[recommenders section](https://emdgroup.github.io/baybe/stable/userguide/recommenders.html)
of the user guide.

```python
from baybe.recommenders import (
    BotorchRecommender,
    FPSRecommender,
    TwoPhaseMetaRecommender,
)

recommender = TwoPhaseMetaRecommender(
    initial_recommender=FPSRecommender(),  # farthest point sampling
    recommender=BotorchRecommender(),  # Bayesian model-based optimization
)
```","Can I combine two recommanders? If yes, how do I do that?",,What is the name of the meta recommender used in BayBE?,TwoPhaseMetaRecommender
20,20,index_chunks_chunk_7,10,"# BayBE √¢¬Ä¬î A Bayesian Back End for Design of Experiments
## √¢¬ö¬° Quick Start
### The Optimization Loop

We can now construct a campaign object that brings all pieces of the puzzle together:

```python
from baybe import Campaign

campaign = Campaign(searchspace, objective, recommender)
```

With this object at hand, we can start our experimentation cycle.
In particular:

* We can ask BayBE to `recommend` new experiments.
* We can `add_measurements` for certain experimental settings to the campaign√¢¬Ä¬ôs
  database.

Note that these two steps can be performed in any order.
In particular, available measurements can be submitted at any time and also several
times before querying the next recommendations.

```python
df = campaign.recommend(batch_size=3)
print(df)
```

```none
   Granularity  Pressure[bar]    Solvent
15      medium            1.0  Solvent D
10      coarse           10.0  Solvent C
29        fine            5.0  Solvent B
```

Note that the specific recommendations will depend on both the data
already fed to the campaign and the random number generator seed that is used.

After having conducted the corresponding experiments, we can add our measured
targets to the table and feed it back to the campaign:

```python
df[""Yield""] = [79.8, 54.1, 59.4]
campaign.add_measurements(df)
```

With the newly arrived data, BayBE can produce a refined design for the next iteration.
This loop would typically continue until a desired target value has been achieved in
the experiment.","What can we do with a campaign object?
","A campaign objects enables us to start the recommendation cycle.
",What function is used to recommend new experiments in BayBE?,`recommend`
21,21,index_chunks_chunk_8,Tia,"# BayBE √¢¬Ä¬î A Bayesian Back End for Design of Experiments
## √¢¬ö¬° Quick Start
### Advanced Example: Chemical Substances

BayBE has several modules to go beyond traditional approaches. One such example is the
use of custom encodings for categorical parameters. Chemical encodings for substances
are a special built-in case of this that comes with BayBE.

In the following picture you can see
the outcome for treating the solvent, base and ligand in a direct arylation reaction
optimization (from [Shields, B.J. et al.](https://doi.org/10.1038/s41586-021-03213-y)) with
chemical encodings compared to one-hot and a random baseline:
![Substance Encoding Example](examples/Backtesting/full_lookup_light.svg)
", does baybe have a special way to encode chemical substances?,"BayBE has built-in support for encoding chemical substances using chemical fingerprints, so it understands them beyond just names. You can see it from the study of Shields, B.J. et al.",What type of encodings does BayBE use for categorical parameters in chemical substances?,Custom encodings.
22,22,known_issues_chunks_chunk_3,1,"# Known Issues
## Installation Related Issues
### macOS-arm64 √¢¬Ä¬ì Leaked Semaphore

We know of a number of instances where BayBE fails during runtime on macOS-arm64
systems. In particular M1 seems to be affected.

The issues often contain a reference to `semaphore`, e.g.
`UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown`.
While we do not know the exact source of the problem, it seems to be related to linked
libraries that need to be compiled from source when no `macOS-arm64` binaries are
available. Packages that seem to have regular problems are `pymatgen` or `matminer`.  :class: tip
Install `baybe` into a clean environment without pre-existing
packages. If you require other packages, try to install `baybe` first.

",I have issues installing BayBE on my mac. How can I solve them?†,"he†issues oftencontain a reference to `semaphore`,†e.g.`UserWarning:†resource_tracker: There appear to be 1 leaked semaphore objects to clean up atshutdown`.While†we do not know the exact source of the problem, it seems to be related to†linkedlibraries†that need to be compiled from source when no`macOS-arm64` binaries†areavailable. Packages that seem to have regular problems are `pymatgen` or `matminer`.""",What issue is reported with BayBE on macOS-arm64 systems?,BayBE fails during runtime and may produce warnings about leaked semaphore objects.
23,23,known_issues_chunks_chunk_4,5,"# Known Issues
## Installation Related Issues
### CPUs without AVX support √¢¬Ä¬ì Installation of `polars`

The package `polars` that can be installed as an optional dependency is only supported for
CPUs with AVX support. As a consequence, you might not be able to install the optional dependency.
This is in particular the case for M1 Macs, as these do not offer this support.  :class: tip
Instead of `polars`, install `polars-lts-cpu`. BayBE will automatically detect the
presence of `polars` and active its advanced machinery. For more details, we refer to the
[polars installation guide](https://docs.pola.rs/user-guide/installation/).","My installation failed, when I tried installing polars. What do I do?",,What is required for the installation of the `polars` package?,AVX support in CPUs.
24,24,known_issues_chunks_chunk_5,2,"# Known Issues
## Installation Related Issues

### Windows √¢¬Ä¬ì Torch Problems

Reports of crashes during runtime on Windows machines often stem from a faulty `torch`
installation, e.g. wrongly installed CUDA-`torch` combinations. Errors look like
`OSError: [WinError 126] The specified module was not found. Error loading  C:\Users\xxxx\AppData\Roaming\Python\Python310\site-packages\torch\lib\shm.dll or one of its dependencies`:class: tip
Install `torch` with the right drivers, for instance a no-CUDA version on CPU. You can
create the commands to do so [here](https://pytorch.org/get-started/locally/).","I have problems with CUDA, what to do?",,What error message is associated with crashes during runtime on Windows due to a faulty torch installation?,OSError: [WinError 126] The specified module was not found.
25,25,known_issues_chunks_chunk_6,6,"# Known Issues
## PyCharm vs. `exceptiongroup`

BayBE√¢¬Ä¬ôs (de-)serialization machinery is build upon `cattrs`, which in turn relies on
`ExceptionGroup`s to report problems in a nicely structured format when using its
[detailed validation](https://catt.rs/en/stable/validation.html#detailed-validation)
feature. However, `ExceptionGroup`s were introduced in Python 3.11 and are
therefore not usable with earlier Python versions. To
enable the feature nevertheless, `cattrs` uses the [exceptiongroup
backport](https://pypi.org/project/exceptiongroup/), which enables the same
functionality by monkeypatching `TracebackException` and installing a special
exception hook on `sys.excepthook`.

The changes attempted by `exceptiongroup` will only be executed if **no prior
modifications have been made**. However, PyCharm appears to make similar modifications
for its own purposes, blocking those of `exceptiongroup` and thus preventing the
exceptions from being properly thrown in detailed validation mode.

The chances of encountering this problem when interacting with BayBE are rather low
as the (de-)serialization objects are usually created by BayBE itself under normal
operation, so there is little risk of them being invalid in the first place. A
potential situation where you might run into the problem is if you manually
write a BayBE configuration and try to deserialize it into a Python BayBE object.
This can happen, for example, while engineering the configuration for later API
calls and testing it locally **using PyCharm**.  :class: tip
You can use **any** of the following workarounds to circumvent the problem:
* Run the code from the terminal instead of inside PyCharm
* Change PyCharm's run configuration from ""Run with Python Console"" to ""Emulate
  terminal in output console""
* Use Python version 3.11 or higher
* Undo the monkeypatch applied by PyCharm by running the following code **at the start
  of your script**:
    ```python
    import sys
    sys.excepthook = sys.__excepthook__
    ```
* Manually [format the exception](https://github.com/agronholm/exceptiongroup/blob/8b8791b662c0f62a574a09f305cd204dfb0a6a05/README.rst?plain=1) thrown by the problematic code:
    ```python
    import exceptiongroup
    from cattrs import ClassValidationError
    
    try:
    <problematic code>
    except ClassValidationError as e:
    raise ValueError("""".join(exceptiongroup.format_exception(e)))
    ```",,,What Python version introduced `ExceptionGroup`s?,Python 3.11
26,26,misc_contributors_link_chunks_chunk_2,1,"# Contributors
## Maintainers

- Martin Fitzner (Merck KGaA, Darmstadt, Germany), [Contact](mailto:martin.fitzner@merckgroup.com), [Github](https://github.com/Scienfitz)
- Adrian √Ö¬†o√Ö¬°i√Ñ¬á (Merck Life Science KGaA, Darmstadt, Germany), [Contact](mailto:adrian.sosic@merckgroup.com), [Github](https://github.com/AdrianSosic)
- Alexander Hopp (Merck KGaA, Darmstadt, Germany), [Contact](mailto:alexander.hopp@merckgroup.com), [Github](https://github.com/AVHopp)",Who can I thank for this awesome package?†,"  - Martin†Fitzner†(Merck†KGaA, Darmstadt, Germany), [Contact](mailto:martin.fitzner@merckgroup.com), [Github](https://github.com/Scienfitz)
- Adrian ≈†o≈°iƒá (Merck Life Science†KGaA, Darmstadt, Germany), [Contact](mailto:adrian.sosic@merckgroup.com),[Github](https://github.com/AdrianSosic)
- Alexander†Hopp†(Merck†KGaA, Darmstadt, Germany), [Contact](mailto:alexander.hopp@merckgroup.com), [Github](https://github.com/AVHopp)","Who is a maintainer from Merck KGaA in Darmstadt, Germany?",Martin Fitzner
27,27,misc_contributors_link_chunks_chunk_3,Tia,"# Contributors
## Contributors

- Alex Lee (EMD Electronics, Tempe, Arizona, USA):<br />
  \\\\
  Work on surrogate models
- Daniel Weber (Merck KGaA, Darmstadt, Germany):<br />
  \\\\
  Telemetry prototype
- Emeline Sola (during an internship at Merck KGaA, Darmstadt, Germany):<br />
  \\\\
  Auto-documentation of the examples
- Sourabh Agrawal (Sigma-Aldrich Chemicals Private Limited):<br />
  \\\\
  Initial implementation of additional surrogate models and clustering methods
- Julie Fang (Merck Life Science KGaA, Darmstadt, Germany):<br />
  \\\\
  Farthest point sampling
- Roya Javadi (Vector Institute, Toronto, Canada):<br />
  \\\\
  Import optimization, Polars implementations
- Sterling Baird (Acceleration Consortium, Toronto, Canada):<br />
  \\\\
  Documentation and general feedback
- Rim Rihana (Merck KGaA, Darmstadt, Germany):<br />
  \\\\
  Human readable output for search spaces
- Di Jin (Merck Life Science KGaA, Darmstadt, Germany):<br />
  \\\\
  Cardinality constraints
- Julian Streibel (Merck Life Science KGaA, Darmstadt, Germany):<br />
  \\\\
  Bernoulli multi-armed bandit and Thompson sampling
- Karin Hrovatin (Merck KGaA, Darmstadt, Germany):<br />
  \\\\
  `scikit-fingerprints` support
- Fabian Liebig (Merck KGaA, Darmstadt, Germany):<br />
  \\\\
  Benchmarking structure and persistence capabilities for benchmarking results
- Alexander Wieczorek (Swiss Federal Institute for Materials Science and Technology, D√É¬ºbendorf, Switzerland):<br />
  \\\\
  SHAP explainers for insights",Who are the contributors of BayBE?,"# Contributors
## Contributors

- Alex Lee (EMD Electronics, Tempe, Arizona, USA):<br />
  \\\\
  Work on surrogate models
- Daniel Weber (Merck KGaA, Darmstadt, Germany):<br />
  \\\\
  Telemetry prototype
- Emeline Sola (during an internship at Merck KGaA, Darmstadt, Germany):<br />
  \\\\
  Auto-documentation of the examples
- Sourabh Agrawal (Sigma-Aldrich Chemicals Private Limited):<br />
  \\\\
  Initial implementation of additional surrogate models and clustering methods
- Julie Fang (Merck Life Science KGaA, Darmstadt, Germany):<br />
  \\\\
  Farthest point sampling
- Roya Javadi (Vector Institute, Toronto, Canada):<br />
  \\\\
  Import optimization, Polars implementations
- Sterling Baird (Acceleration Consortium, Toronto, Canada):<br />
  \\\\
  Documentation and general feedback
- Rim Rihana (Merck KGaA, Darmstadt, Germany):<br />
  \\\\
  Human readable output for search spaces
- Di Jin (Merck Life Science KGaA, Darmstadt, Germany):<br />
  \\\\
  Cardinality constraints
- Julian Streibel (Merck Life Science KGaA, Darmstadt, Germany):<br />
  \\\\
  Bernoulli multi-armed bandit and Thompson sampling
- Karin Hrovatin (Merck KGaA, Darmstadt, Germany):<br />
  \\\\
  `scikit-fingerprints` support
- Fabian Liebig (Merck KGaA, Darmstadt, Germany):<br />
  \\\\
  Benchmarking structure and persistence capabilities for benchmarking results
- Alexander Wieczorek (Swiss Federal Institute for Materials Science and Technology, D√É¬ºbendorf, Switzerland):<br />
  \\\\
  SHAP explainers for insights",Who worked on the telemetry prototype?,Daniel Weber
28,28,misc_license_link_chunks_chunk_1,,"# License
Copyright 2022-2025 Merck KGaA, Darmstadt, Germany and/or its affiliates. All rights reserved.

Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0   Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
```text

                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      ""License"" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      ""Licensor"" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      ""Legal Entity"" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      ""control"" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      ""You"" (or ""Your"") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      ""Source"" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      ""Object"" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      ""Work"" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      ""Derivative Works"" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      ""Contribution"" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, ""submitted""
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as ""Not a Contribution.""

      ""Contributor"" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a ""NOTICE"" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an ""AS IS"" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS
```",What legal rules I must follow when I use or distribute BayBE?,"Copyright 2022-2025 Merck KGaA, Darmstadt, Germany and/or its affiliates. All rights reserved.

Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0   Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","What is the URL to obtain a copy of the Apache License, Version 2.0?",http://www.apache.org/licenses/LICENSE-2.0
29,29,userguide_active_learning_chunks_chunk_1,1,"# Active Learning

When deciding which experiments to perform next, e.g. for a data acquisition campaign
to gather data for a machine learning model, it can be beneficial to follow a guided
approach rather than selecting experiments randomly. If this is done via iteratively
measuring points according to a criterion reflecting the current model√¢¬Ä¬ôs uncertainty,
the method is called **active learning**.

Active learning can be seen as a special case of Bayesian optimization: If we have the
above-mentioned criterion and set up a Bayesian optimization campaign to recommend
points with the highest uncertainty, we achieve active learning via Bayesian
optimization. In practice, this is procedure is implemented by setting up a
probabilistic model of our measurement process that allows us to quantify uncertainty
in the form of a posterior distribution, from which we can then construct an
uncertainty-based acquisition function to guide the exploration process.",How can I make sure that my model learns as much as possible about a process?†,"Active learning can be seen as a special case of Bayesian optimization: If we have the above-mentioned criterion and set up a Bayesian optimizationcampaign to recommend points with the highest uncertainty, we achieve active learning via Bayesian optimization. In practice, this is procedure isimplemented by setting up a probabilistic model of our measurement process that allows us to quantify uncertainty in the form of a posterior distribution,from which we can then construct an uncertainty-based acquisition function to guide the exploration process.",What is the method called that involves selecting experiments based on the current model's uncertainty?,Active learning
30,30,userguide_active_learning_chunks_chunk_2,2,"# Active Learning
## Local Uncertainty Reduction

In BayBE, there are two types of acquisition function that can be chosen to search for
the points with the highest predicted model uncertainty:

- [`PosteriorStandardDeviation`]() (`PSTD`)
  / [`qPosteriorStandardDeviation`]() (`qPSTD`)
- [`UpperConfidenceBound`]() (`UCB`) /
  [`qUpperConfidenceBound`]() (`qUCB`)
  with high `beta`:<br />
  \\\\
  Increasing values of `beta` effectively eliminate the effect of the posterior mean on
  the acquisition value, yielding a selection of points driven primarily by the
  posterior variance. However, we generally recommend to use this acquisition function
  only if a small exploratory component is desired √¢¬Ä¬ì otherwise, the
  [`qPosteriorStandardDeviation`]()
  acquisition function is what you are looking for.",How to tweak parameters of the UCB acquisition function,,What are the two types of acquisition function in BayBE for searching points with the highest predicted model uncertainty?,`PosteriorStandardDeviation` (`PSTD`) and `UpperConfidenceBound` (`UCB`).
31,31,userguide_active_learning_chunks_chunk_3,5,"# Active Learning
## Global Uncertainty Reduction

BayBE also offers the
[`qNegIntegratedPosteriorVariance`]()
(`qNIPV`), which integrates
the posterior variance over the entire search space.
Choosing candidates based on this acquisition function is tantamount to selecting the
set of points resulting in the largest reduction of global uncertainty when added to
the already existing experimental design.

Because of its ability to quantify uncertainty on a global scale, this approach is often
superior to using a point-based uncertainty criterion as acquisition function.
However, due to its computational complexity, it can be prohibitive to integrate over
the entire search space. For this reason, we offer the option to sub-sample parts of it,
configurable via the constructor:

```python
from baybe.acquisition import qNIPV
from baybe.utils.sampling_algorithms import DiscreteSamplingMethod

# Will integrate over the entire search space
qNIPV()

# Will integrate over 50% of the search space, randomly sampled
qNIPV(sampling_fraction=0.5)

# Will integrate over 250 points, chosen by farthest point sampling
# Both lines are equivalent
qNIPV(sampling_n_points=250, sampling_method=""FPS"")
qNIPV(sampling_n_points=250, sampling_method=DiscreteSamplingMethod.FPS)
```:class: note
Sampling of the continuous part of the search space will always be random, while 
sampling of the discrete part can be controlled by providing a corresponding 
[`DiscreteSamplingMethod`](baybe.utils.sampling_algorithms.DiscreteSamplingMethod) for 
`sampling_method`.:class: important
Please be aware that in case of a purely continuous search space, the number of points 
to sample for integration must be specified via `sampling_n_points` (since providing
a fraction becomes meaningless).",What is a good fraction of random sampling to replace partly the inegration of the search space? ,,What does the `qNegIntegratedPosteriorVariance` function integrate over?,The entire search space.
32,32,userguide_async_chunks_chunk_1,1,"# Asynchronous Workflows

Asynchronous workflows describe situations where the loop between measurement and
recommendation is more complex and needs to incorporate various other aspects. These
could for instance be:

- **Distributed workflows**: When recommendations are distributed across several
  operators, e.g. at different locations or in several reactors, some experiments might
  have been started, but are not ready when the next batch of recommendations is requested.
  Without further consideration, the algorithm would be likely to recommend the pending
  experiments again (since they were and still are considered most promising), as it is
  unaware they were already started.
- **Partial targets**: When dealing with multiple targets that require very different
  amounts of time to measure, the targets of previously recommended points might only be
  partially available when requesting the next batch of recommendations. Still, these
  partial experiments should ideally be considered when generating the recommendations.

With *pending experiments* we mean experiments whose measurement process has
been started, but not yet completed by time of triggering the next set of
recommendations √¢¬Ä¬ì this is typically the case when at least one of the configured
targets has not yet been measured.

There are two levels of dealing with such situations:

1. **Marking experiments as pending**: If an experiment is not completed (meaning at least one target is not yet measured), its
   data cannot be added as a regular measurement. However, it can be marked as pending via
   `pending_experiments` in `recommend`.
2. **Adding partial results**: If an experiment is partially completed (meaning at least one target has been
   measured), we can already update the model with the available information
   by adding a *partial* measurement.
",What can I do if some of my†experiments are still running but I need new reccomendations for additional experiments?†,"1. **Marking experiments as pending**: If an experiment is not completed (meaning at least one target is not yet measured), its data cannot be addedas a regular measurement. However, it can be marked as pending via `pending_experiments` in `recommend`.",What are pending experiments in asynchronous workflows?,Pending experiments are experiments whose measurement process has been started but not yet completed by the time the next set of recommendations is triggered.
33,33,userguide_async_chunks_chunk_2,2,"# Asynchronous Workflows
## Marking Experiments as Pending

To avoid repeated recommendations in the above scenario, BayBE provides the
`pending_experiments` keyword. It is available wherever recommendations can be
requested, i.e. [`Campaign.recommend`]() or
[`RecommenderProtocol.recommend`]().

Akin to `measurements` or `recommendations`, `pending_experiments` is a dataframe in
[experimental representation](searchspace.md#data-representation).
In the following example, we get a set of recommendations, add results for half of them,
and start the next recommendation, marking the other half pending:

```python
from baybe.utils.dataframe import add_fake_measurements

# Get a set of 10 recommendation
rec = campaign.recommend(batch_size=10)

# Split recommendations into two parts
rec_finished = rec.iloc[:5]
rec_pending = rec.iloc[5:]

# Add target measurements to the finished part. Here we add fake results
add_fake_measurements(rec_finished, campaign.targets)
campaign.add_measurements(rec_finished)

# Get the next set of recommendations, incorporating the still unfinished experiments.
# These will not include the experiments marked as pending again.
rec_next = campaign.recommend(10, pending_experiments=rec_pending)
```","What are ""pending_experiments"" good for?",,What keyword does BayBE provide to mark experiments as pending?,`pending_experiments`
34,34,userguide_async_chunks_chunk_3,Tia,"# Asynchronous Workflows
## Adding Partial Results

A *partial result* is possible if you have multiple targets, but only measured the
outcome for some of those. This is a common occurrence, especially if the different
target measurements correspond to experiments that differ in complexity or duration.

As a simple example, consider a campaign with medical background aimed at creating a
drug formulation. Typically, there are quick initial analytics performed on the
formulation, followed by *in vitro* experiments followed by mouse *in vivo* experiments.
Without the ability to use partial measurements, you would have to wait until the slow
mouse experiment for a given recommendation is measured until you could utilize any of
the other (faster) experimental outcomes for that recommendation. Furthermore, if the fast
measurements are already unpromising, the slower target measurements are possibly never
performed at all.

In BayBE, you can leverage results even if they are only partial. This is indicated
by setting the corresponding target measurement value to NaN. There are several ways to indicate this, e.g.:

* [`numpy.nan`](https://numpy.org/doc/stable/reference/constants.html#numpy.nan)
* [`pandas.NA`](https://pandas.pydata.org/docs/reference/api/pandas.NA.html#pandas.NA)
* `None`
* `float(""nan"")`

Let us consider this 3-batch of recommendations, assuming
we need to measure √¢¬Ä¬úTarget_1√¢¬Ä¬ù, √¢¬Ä¬úTarget_2√¢¬Ä¬ù and √¢¬Ä¬úTarget_3√¢¬Ä¬ù:

```python
import numpy as np
import pandas as pd

rec = campaign.recommend(batch_size=3)
# Resetting the index to have easier access via .loc later
measurements = rec.reset_index(drop=True)

# Add measurement results
measurements.loc[0, ""Target_1""] = 10.3
measurements.loc[0, ""Target_2""] = 0.5
measurements.loc[0, ""Target_3""] = 11.1

measurements.loc[1, ""Target_1""] = 7.1
measurements.loc[1, ""Target_2""] = np.nan  # not measured yet
measurements.loc[1, ""Target_3""] = 12.2

measurements.loc[2, ""Target_1""] = 11.4
measurements.loc[2, ""Target_2""] = pd.NA  # not measured yet
measurements.loc[2, ""Target_3""] = None  # not measured yet

measurements

# Proceed with campaign.add_measurements ...
```

| Param_1   |   Param_2 | ...   |   Target_1 |   Target_2 |   Target_3 |
|-----------|-----------|-----|------------|------------|------------|
| on        |       1.1 | ...   |       10.3 |        0.5 |       11.1 |
| on        |       3.8 | ...   |        7.1 |      nan   |       12.2 |
| off       |       2.9 | ...   |       11.4 |      nan   |      nan   |

Internally, the incomplete rows are dropped when fitting a surrogate model for each
target. If you use an unsupported surrogate model, an error will be thrown at runtime.:class: important
The described method only works if the surrogate model uses a separate data basis
for each target. This is e.g. the case if you use the
[`CompositeSurrogate`](baybe.surrogates.composite.CompositeSurrogate)
to enable multi-output modeling required by the 
[`ParetoObjective`](baybe.objectives.pareto.ParetoObjective). For details, see 
[multi-output modeling](multi_output_modeling).

The [`DesirabilityObjective`](baybe.objectives.desirability.DesirabilityObjective) does 
not currently utilize multi-output models and hence does not support partial results.  ",why I can not add partical result to my experiment model?,"Adding Partial Results only works if the surrogate model uses a separate data basis
for each target. This is e.g. the case if you use the
[`CompositeSurrogate`](baybe.surrogates.composite.CompositeSurrogate)
to enable multi-output modeling required by the 
[`ParetoObjective`](baybe.objectives.pareto.ParetoObjective). For details, see 
[multi-output modeling](multi_output_modeling).

The [`DesirabilityObjective`](baybe.objectives.desirability.DesirabilityObjective) does 
not currently utilize multi-output models and hence does not support partial results.",What is indicated by setting a target measurement value to NaN in BayBE?,"It indicates that the measurement for that target has not been measured yet, allowing the use of partial results."
35,35,userguide_campaigns_chunks_chunk_10,1,"# Campaigns
## Predictive Statistics

You might be interested in statistics about the predicted target values for your
recommendations, or indeed for any set of possible candidate points. The
[`Campaign.posterior_stats`]() and
[`Surrogate.posterior_stats`]() methods
provide a simple interface for this:

```python
stats = campaign.posterior_stats(rec)
```

This will return a table with mean and standard deviation (and possibly other
statistics) of the target predictions for the provided candidates:

|    |   Yield_mean |   Yield_std |   Selectivity_mean |   Selectivity_std | ...   |
|----|--------------|-------------|--------------------|-------------------|-----|
| 15 |        83.54 |        5.23 |              91.22 |              7.42 | ...   |
| 18 |        56.12 |        2.34 |              87.32 |             12.38 | ...   |
|  9 |        59.1  |        5.34 |              83.72 |              9.62 | ...   |

You can also provide an optional sequence of statistic names to compute other
statistics. If a float is provided, the corresponding quantile points will be
calculated:

```python
stats = campaign.posterior_stats(rec, stats=[""mode"", 0.5])
```

|    |   Yield_mode |   Yield_Q_0.5 |   Selectivity_mode |   Selectivity_Q_0.5 | ...   |
|----|--------------|---------------|--------------------|---------------------|-----|
| 15 |        83.54 |         83.54 |              91.22 |               91.22 | ...   |
| 18 |        56.12 |         56.12 |              87.32 |               87.32 | ...   |
|  9 |        59.1  |         59.1  |              83.72 |               83.72 | ...   |",No,,What methods provide an interface for predicted target values in campaigns?,The `Campaign.posterior_stats` and `Surrogate.posterior_stats` methods.
36,36,userguide_campaigns_chunks_chunk_11,2,"# Campaigns
## Acquisition Function Values

In some cases, you may want to examine the specific acquisition function values for a given set of candidates. Campaigns provide two straightforward methods for this purpose:

- `acquisition_values()`: Computes **individual** acquisition values for each candidate in the set, answering the question  *√¢¬Ä¬úWhat is the expected utility of running this experiment in isolation?√¢¬Ä¬ù*
- `joint_acquisition_value()`: Computes the **joint** acquisition value for the entire candidate batch, answering the question  *√¢¬Ä¬úWhat is the overall expected utility of running this batch of experiments√¢¬Ä¬ù?*

```python
rec = campaign.recommend(5)
acq_values = campaign.acquisition_values(rec)  # contains 5 numbers
joint_acq_value = campaign.joint_acquisition_value(rec)  # contains 1 number
```

By default, both methods use the acquisition function of the underlying recommender. However, you can also specify a custom acquisition function if needed:

```python
from baybe.acquisition import UCB, qPSTD

acq_values = campaign.acquisition_values(rec, UCB())
joint_acq_value = campaign.joint_acquisition_value(rec, qPSTD())
```",How can I manually compute the value of my acquisition function?,,What method computes individual acquisition values for candidates in a campaign?,`acquisition_values()`
37,37,userguide_campaigns_chunks_chunk_12,5,"# Campaigns
## Serialization

Like other BayBE objects, [`Campaigns`]() can be (de-)serialized
using their [`from_json`]()/
[`to_json`]() methods, which
allow to convert between Python objects and their corresponding representation in JSON
format:

```python
campaign_json = campaign.to_json()
reconstructed = Campaign.from_json(campaign_json)
assert campaign == reconstructed
```

General information on this topic can be found in our
[serialization user guide](serialization.md).
For campaigns, however, this possibility is particularly noteworthy as it enables
one of the most common workflows in this context √¢¬Ä¬ì
persisting the current state of a campaign for long-term storage and continuing the
experimentation at a later point in time:

1. Get your campaign object
   * When initiating the workflow, create a new campaign object
   * When coming from the last step below, **deserialize** the existing campaign object
2. Add the latest measurement results
3. Get a recommendation
4. **Serialize** the campaign and store it somewhere
5. Run your (potentially lengthy) real-world experiments
6. Repeat

## Further Information

Campaigns are created as a first step in most of our
[examples]().
For more details on how to define campaigns for a specific use case, we thus propose
to have a look at the most suitable example.",What would be the best practice to set up a long-term experiment with Baybe? ,,How can campaigns be serialized in BayBE?,Campaigns can be serialized using the `to_json()` method and deserialized using the `from_json()` method.
38,38,userguide_campaigns_chunks_chunk_3,8,"# Campaigns

When it comes to Bayesian optimization, campaigns emerge as an essential component.
They encompass a group of interconnected experiments that collectively aim to navigate
the search space and find an optimal solution. They take center stage in orchestrating
the iterative process of selecting, evaluating, and refining candidate solutions.
Thus, campaigns are an integral part of Bayesian optimization and, accordingly,
they also play a central role in BayBE.

The [`Campaign`]() class provides a structured framework for
defining and documenting an experimentation process.
It further serves as the primary interface for interacting with BayBE as a user
since it is responsible for handling experimental data, making recommendations, adding
measurements, and most other user-related tasks.

## Creating a Campaign
### Basic Creation

Creating a campaign requires specifying at least two pieces of information that
describe the underlying optimization problem at hand:

| Campaign Specification                     | BayBE Class                                              |
|--------------------------------------------|----------------------------------------------------------|
| What should be optimized in the campaign?  | `Objective` ([class]() / [user guide](objectives.md))    |
| Which experimental factors can be altered? | `SearchSpace` ([class]() / [user guide](searchspace.md)) |

Apart from this basic configuration, it is possible to further define the specific
optimization
`Recommender`√Ç¬†([class]()
/ [user guide](recommenders.md)) to be used.

```python
from baybe import Campaign

campaign = Campaign(
    searchspace=searchspace,  # Required
    objective=objective,  # Required
    recommender=recommender,  # Optional
)
```",,,What are the two required pieces of information needed to create a campaign in BayBE?,The objective and the search space.
39,39,userguide_campaigns_chunks_chunk_4,6,"# Campaigns
## Creating a Campaign
### Creation From a JSON Config

Instead of using the default constructor, it is also possible to create a `Campaign`
from a JSON configuration string via
[`Campaign.from_config`]().
Herein, the expected JSON schema of the string should mirror the class
hierarchy of the objects nested in the corresponding campaign object.
The string can be easily validated using
[Campaign.validate_config]() without
instantiating the object, which skips the potentially costly search space creation step.
For more details and a full exemplary config, we refer to the corresponding
[example]().",,,How can a Campaign be created from a JSON configuration string?,A Campaign can be created from a JSON configuration string using `Campaign.from_config()`.
40,40,userguide_campaigns_chunks_chunk_6,,"# Campaigns
## Getting Recommendations
### Basics

To obtain a recommendation for the next batch of experiments, we can query the
campaign via the [`recommend`]() method.
It expects a parameter `batch_size` that specifies the desired number of
experiments to be conducted.

```python
rec = campaign.recommend(batch_size=3)
```

Calling the function returns a `DataFrame` with `batch_size` many rows, each
representing a particular parameter configuration from the campaign√¢¬Ä¬ôs search space.
Thus, the following might be a `DataFrame` returned by `recommend` in a search space
with the three parameters `Categorical_1`, `Categorical_2` and `Num_disc_1`:

|    | Categorical_1   | Categorical_2   |   Num_disc_1 |
|----|-----------------|-----------------|--------------|
| 15 | B               | good            |            1 |
| 18 | C               | bad             |            1 |
|  9 | B               | bad             |            1 |:class: important
In general, the parameter configurations in a recommended batch are **jointly**
optimized and therefore tailored to the specific batch size requested. 
This means that for two batches of different requested sizes, the smaller batch will not 
necessarily correspond to a subset of the configurations contained in the larger batch. 
An intuitive explanation for this phenomenon is that the more experiments one can 
afford to run, the less need there is to focus on ""safe bets"" and the more room
becomes available to test ""high-risk/high-gain"" configurations, since only one of the
tested configurations from the batch has to perform well.

**The bottom line is:** You should always ask for exactly as many
recommendations as you are willing to run parallel experiments in your next 
experimental iteration.
An approach where only a subset of experiments taken from a larger recommended batch is
used is strongly discouraged.

**Note:** While the above distinction is true in the general case, it may not be 
relevant for all configured settings, for instance, when the used recommender 
is not capable of joint optimization. Currently, the 
[BotorchRecommender](baybe.recommenders.pure.bayesian.botorch.BotorchRecommender)
is the only recommender available that performs joint optimization.:class: note
If you have a fixed experimental budget but the luxury of choosing 
whether to run your experiments sequentially or in parallel, sequential 
experimentation will give you the better overall results in expectation.
This is because in the sequential approach, each subsequent recommendation can 
leverage the additional data from previous iterations, which allows 
more accurate predictive models to be built. However, in real-world use cases, the 
question is typically answered by other factors, such as whether parallel
experimentation is feasible in the first place, or whether the given time budget 
even allows for sequential runs.",Can I just run part of the recommend batch but not harm my model? ,"This means that for two batches of different requested sizes, the smaller batch will not 
necessarily correspond to a subset of the configurations contained in the larger batch. 
An intuitive explanation for this phenomenon is that the more experiments one can 
afford to run, the less need there is to focus on ""safe bets"" and the more room
becomes available to test ""high-risk/high-gain"" configurations, since only one of the
tested configurations from the batch has to perform well.",What method is used to obtain a recommendation for the next batch of experiments in a campaign?,The `recommend` method.
41,41,userguide_campaigns_chunks_chunk_7,9,"# Campaigns
## Getting Recommendations
### Candidate Control in Discrete Spaces

For discrete search spaces, campaigns provide additional control over how the candidate
set of recommendable points is built based on the trajectory the campaign has taken so
far. This is done by setting the following Boolean flags:

- `allow_recommending_already_measured`:  Controls whether points that have already been
  measured can be recommended.
- `allow_recommending_already_recommended`: Controls whether previously recommended points can
  be recommended again.
- `allow_recommending_pending_experiments`: Controls whether points marked as
  `pending_experiments` can be recommended (see [asynchronous
  workflows](async.md#pending-experiments)). # Campaigns
## Getting Recommendations
### Caching of Recommendations

The `Campaign` object caches the last batch of recommendations returned, in order to
avoid unnecessary computations for subsequent queries between which the status
of the campaign has not changed.
The cache is invalidated as soon as new measurements are added or a different
batch size is desired.
The latter is necessary because each batch is optimized for the specific number of
experiments requested (see note above).",How do I specify that points can be recommended again (in subsequent experiments) when previous experiments are still pending?,,What does the `allow_recommending_already_measured` flag control in campaigns?,It controls whether points that have already been measured can be recommended.
42,42,userguide_campaigns_chunks_chunk_9,10,"# Campaigns
## Adding Measurements

Available experimental data can be added at any time during the campaign lifecycle using
the [`add_measurements`]() method,
which expects a `DataFrame` containing the values of the used experimental parameters
and all corresponding target measurements.
If measurements are to be added immediately after a call to `recommend`,
this is most easily achieved by augmenting the  `DataFrame` returned from that call
with the respective target columns.

```python
rec[""Target_max""] = [2, 4, 9]  # 3 values matching the batch_size of 3
campaign.add_measurements(rec)
new_rec = campaign.recommend(batch_size=5)
```

After adding the measurements, the corresponding `DataFrame` thus has the following
form:

|    | Categorical_1   | Categorical_2   |   Num_disc_1 |   Target_max |
|----|-----------------|-----------------|--------------|--------------|
| 15 | B               | good            |            1 |            2 |
| 18 | C               | bad             |            1 |            4 |
|  9 | B               | bad             |            1 |            9 |",Are there any restrictions on the parameter values that I can add via the `add_measurements` method?,"For discrete parameters, the parameter values associated with the provided measurements are required to fall into a predefined tolerance interval by default, which is defined on the level of the individual parameters",What method is used to add experimental data during a campaign lifecycle?,`add_measurements`
43,43,userguide_constraints_chunks_chunk_1,1,"# Constraints

Experimental campaigns often have naturally arising constraints on the parameters and
their combinations. Such constraints could for example be:

* When optimizing a mixture, the relative concentrations of the used ingredients must
  add up to 1.0.
* For chemical reactions, a reagent might be incompatible with high temperatures, hence
  these combinations must be excluded.
* Certain settings are dependent on other parameters, e.g. a set of parameters only
  becomes relevant if another parameter called `""Switch""` has the value `""on""`.

Similar to parameters, BayBE distinguishes two families of constraints, derived from the
abstract [`Constraint`]() class: discrete and
continuous constraints ([`DiscreteConstraint`](),
[`ContinuousConstraint`]()).
A constraint is called discrete/continuous if it operates on a set of exclusively
discrete/continuous parameters.       
 #### WARNING
:class: note
Currently, BayBE does not support hybrid constraints, that is, constraints which
operate on a mixed set of discrete and continuous parameters. If such a constraint is
necessary, it is possible to rephrase the parametrization so that the parameter set
is exclusively discrete or continuous in most cases.",How can I make sure that all my experimental constraints are reflected in the campaign set-up?†,"Similar to†parameters,†BayBE†distinguishes two families of constraints, derived from the abstract [`Constraint`]() class: discrete and
continuous constraints ([`DiscreteConstraint`](), [`ContinuousConstraint`]()).
A constraint is called discrete/continuous if it operates on a set of exclusively discrete/continuous parameters.",What must the relative concentrations of ingredients add up to when optimizing a mixture?,1
44,44,userguide_constraints_chunks_chunk_10,5,"# Constraints
## Discrete Constraints
### DiscreteSumConstraint and DiscreteProductConstraint

[`DiscreteSumConstraint`]()
and [`DiscreteProductConstraint`]()
impose conditions on sums or products of numerical parameters.
[In the first example from `ContinuousLinearConstraint`](#clc), we
had three continuous parameters `x_1`, `x_2` and `x_3`, which needed to sum
up to 1.0.
If these parameters were instead discrete, the corresponding constraint would look like:

```python
from baybe.constraints import DiscreteSumConstraint, ThresholdCondition

DiscreteSumConstraint(
    parameters=[""x_1"", ""x_2"", ""x_3""],
    condition=ThresholdCondition(  # set condition that should apply to the sum
        threshold=1.0,
        operator=""="",
        tolerance=0.001,  # optional; here, everything between 0.999 and 1.001 would also be considered valid
    ),
)
```

An end to end example can be found [here]().",How do I implement variable constraints that work for noisy data?,,What is the purpose of `DiscreteSumConstraint` in the provided context?,It imposes conditions on sums of discrete numerical parameters.
45,45,userguide_constraints_chunks_chunk_11,6,"# Constraints
## Discrete Constraints
### DiscreteNoLabelDuplicatesConstraint

Sometimes, duplicated labels in several parameters are undesirable.
Consider an example with two solvents that describe different mixture
components.
These might have the exact same or overlapping sets of possible values, e.g.
`[""Water"", ""THF"", ""Octanol""]`.
It would not necessarily be reasonable to allow values in which both solvents show the
same label/component.
We can exclude such occurrences with the
[`DiscreteNoLabelDuplicatesConstraint`]():

```python
from baybe.constraints import DiscreteNoLabelDuplicatesConstraint

DiscreteNoLabelDuplicatesConstraint(parameters=[""Solvent_1"", ""Solvent_2""])
```

Without this constraint, combinations like below would be possible:

|    | Solvent_1   | Solvent_2   | With DiscreteNoLabelDuplicatesConstraint   |
|----|-------------|-------------|--------------------------------------------|
|  1 | Water       | Water       | would be excluded                          |
|  2 | THF         | Water       |                                            |
|  3 | Octanol     | Octanol     | would be excluded                          |

The usage of `DiscreteNoLabelDuplicatesConstraint` is part of the
[example on slot-based mixtures]().",,,What is the purpose of the DiscreteNoLabelDuplicatesConstraint?,To exclude combinations of parameters where duplicated labels occur in multiple solvents.
46,46,userguide_constraints_chunks_chunk_12,9,"# Constraints
## Discrete Constraints
### DiscreteLinkedParametersConstraint

The [`DiscreteLinkedParametersConstraint`]()
is, in a sense, the opposite of the
[`DiscreteNoLabelDuplicatesConstraint`]().
It will ensure that **only** entries with duplicated labels are present.
This can be useful, for instance, in situations where we have one parameter but would
like to include it with several encodings:

```python
from baybe.parameters import SubstanceParameter
from baybe.constraints import DiscreteLinkedParametersConstraint

dict_solvents = {""Water"": ""O"", ""THF"": ""C1CCOC1"", ""Octanol"": ""CCCCCCCCO""}
solvent_encoding1 = SubstanceParameter(
    name=""Solvent_RDKIT_enc"",
    data=dict_solvents,
    encoding=""RDKIT"",
)
solvent_encoding2 = SubstanceParameter(
    name=""Solvent_MORDRED_enc"",
    data=dict_solvents,
    encoding=""MORDRED"",
)
DiscreteLinkedParametersConstraint(
    parameters=[""Solvent_RDKIT_enc"", ""Solvent_MORDRED_enc""]
)
```

|    | Solvent_RDKIT_enc   | Solvent_MORDRED_enc   | With DiscreteLinkedParametersConstraint   |
|----|---------------------|-----------------------|-------------------------------------------|
|  1 | Water               | Water                 |                                           |
|  2 | THF                 | Water                 | would be excluded                         |
|  3 | Octanol             | Octanol               |                                           |",How do I keep only parameters which have duplicate values across my dataset?,,What is the purpose of the DiscreteLinkedParametersConstraint?,It ensures that only entries with duplicated labels are present.
47,47,userguide_constraints_chunks_chunk_13,,"# Constraints
## Discrete Constraints
### DiscreteDependenciesConstraint

A dependency is a situation where parameters depend on other parameters.
Let√¢¬Ä¬ôs say an experimental setup has a parameter called `""Switch""`, which turns on
pieces of equipment that are optional.
This means the other parameters (called `affected_parameters`) are only relevant if
the switch parameter has the value `""on""`. If the switch is `""off""`, the affected
parameters are irrelevant.

You can specify such a dependency with the
[`DiscreteDependenciesConstraint`]()
, which requires:

1. A list `parameters` with the names of the parameters upon which others depend.
2. A list `conditions`, specifying the values of the corresponding entries in
   `parameters` that √¢¬Ä¬úactivate√¢¬Ä¬ù the dependent parameters.
3. A list of lists, each containing the `affected_parameters`, which become relevant
   only if the corresponding entry in `parameters` is active as specified by the
   entry in `conditions`.

Internally, BayBE drops elements from the `SearchSpace` where affected parameters are
irrelevant. Since in our example `""off""` is still a valid value for the switch, the
`SearchSpace` will still retain **one** configuration for that setting, showing arbitrary
values for the `affected_parameters` (which can be ignored).

<a id=""ddc""></a>

#### IMPORTANT
BayBE requires that all dependencies are declared in a single
`DiscreteDependenciesConstraint`. Creating a `SearchSpace` from multiple
`DiscreteDependenciesConstraint`√¢¬Ä¬ôs will throw a validation error.

In the example below, we mimic a situation where there are two switches and each switch
activates two other parameters that are only relevant if the first switch is `""on""` / the
second switch is set to `""right""`, respectively.

```python
from baybe.constraints import DiscreteDependenciesConstraint, SubSelectionCondition

DiscreteDependenciesConstraint(
    parameters=[""Switch_1"", ""Switch_2""],  # the two parameters upon which others depend
    conditions=[
        SubSelectionCondition(
            # values of Switch_1 that activate the affected parameters
            selection=[""on""]
        ),
        SubSelectionCondition(
            # values of Switch_2 that activate the affected parameters
            selection=[""right""]
        ),
    ],
    affected_parameters=[
        [""Solvent"", ""Fraction""],  # parameters affected by Switch_1
        [""Frame_1"", ""Frame_2""],  # parameters affected by Switch_2
    ],
)
```
","Can I create  a `SearchSpace` from multiple
`DiscreteDependenciesConstraint`? ","BayBE requires that all dependencies are declared in a single
`DiscreteDependenciesConstraint`. Creating a `SearchSpace` from multiple
`DiscreteDependenciesConstraint`'s will throw a validation error.",What is the purpose of the `DiscreteDependenciesConstraint` in BayBE?,It specifies dependencies where certain parameters become relevant only if specific conditions on other parameters are met.
48,48,userguide_constraints_chunks_chunk_14,,"# Constraints
## Discrete Constraints
### DiscretePermutationInvarianceConstraint

Permutation invariance, enabled by the
[`DiscretePermutationInvarianceConstraint`]()
, is a property where combinations of values of multiple
parameters do not depend on their order due to some symmetry in the experiment.
Suppose we create a mixture containing up to three solvents, i.e. parameters
√¢¬Ä¬úSolvent_1√¢¬Ä¬ù, √¢¬Ä¬úSolvent_2√¢¬Ä¬ù, √¢¬Ä¬úSolvent_3√¢¬Ä¬ù.
In this situation, all combinations from the following table would be equivalent,
hence the `SearchSpace` should effectively only contain one of them.

|    | Solvent_1    | Solvent_2    | Solvent_3    |
|----|--------------|--------------|--------------|
|  1 | Substance_43 | Substance_3  | Substance_12 |
|  2 | Substance_43 | Substance_12 | Substance_3  |
|  3 | Substance_3  | Substance_12 | Substance_43 |
|  4 | Substance_3  | Substance_43 | Substance_12 |
|  5 | Substance_12 | Substance_43 | Substance_3  |
|  6 | Substance_12 | Substance_3  | Substance_43 |

#### NOTE
Complex properties such as permutation invariance not only affect the search space but
should ideally also constrain the surrogate model. For instance, the kernels in a
Gaussian process can be made permutation-invariant to reflect this constraint, which
generally results in a better learning curve. Note that at this stage no
surrogate model provided by BayBE takes care of these invariances. This means the
invariance is ignored during model fitting and these models do not benefit
from a priori known constraints and invariances between parameters. However, generally,
the optimization will still work. We are in the process of enabling this as new feature,
but in the meantime the user can introduce their own
[custom surrogate model]()
to include these.

Let√¢¬Ä¬ôs add to the mixture example the fact that not only the choice of substance but also
their relative mixture fractions are parameters, i.e. √¢¬Ä¬úFraction_1√¢¬Ä¬ù, √¢¬Ä¬úFraction_2√¢¬Ä¬ù and
√¢¬Ä¬úFraction_3√¢¬Ä¬ù.
This also implies that the solvent parameters depend on their corresponding
fraction being `> 0.0`, because in the case `== 0.0` the choice of solvent is
irrelevant. This models a scenario that allows √¢¬Ä¬úup to, but not necessarily,
three solvents√¢¬Ä¬ù.

#### IMPORTANT
If some of the `parameters` of the `DiscretePermutationInvarianceConstraint` are
dependent on other parameters, we require that the dependencies are provided as a
`DiscreteDependenciesConstraint` to the `dependencies` argument of the
`DiscretePermutationInvarianceConstraint`. This
`DiscreteDependenciesConstraint` will not count towards the maximum limit of one
`DiscreteDependenciesConstraint` discussed [here](#ddc).

The `DiscretePermutationInvarianceConstraint` below applies to our example and
removes permutation-invariant combinations of solvents that have additional
dependencies as well:

```python
from baybe.constraints import (
    DiscretePermutationInvarianceConstraint,
    DiscreteDependenciesConstraint,
    ThresholdCondition,
)

DiscretePermutationInvarianceConstraint(
    parameters=[""Solvent_1"", ""Solvent_2"", ""Solvent_3""],
    # `dependencies` is optional; it is only required if some of the permutation
    # invariant entries in `parameters` have dependencies on other parameters
    dependencies=DiscreteDependenciesConstraint(
        parameters=[""Fraction_1"", ""Fraction_2"", ""Fraction_3""],
        conditions=[
            ThresholdCondition(threshold=0.0, operator="">""),
            ThresholdCondition(threshold=0.0, operator="">""),
            ThresholdCondition(threshold=0.0, operator="">""),
        ],
        affected_parameters=[[""Solvent_1""], [""Solvent_2""], [""Solvent_3""]],
    ),
)
```
","I already have a DiscreteDependenciesConstraint in my model, can I use another DiscreteDependenciesConstraint inside  DiscretePermutationInvarianceConstraint? ","Yes. If some of the `parameters` of the `DiscretePermutationInvarianceConstraint` are
dependent on other parameters, we require that the dependencies are provided as a
`DiscreteDependenciesConstraint` to the `dependencies` argument of the
`DiscretePermutationInvarianceConstraint`. This
`DiscreteDependenciesConstraint` will not count towards the maximum limit of one
`DiscreteDependenciesConstraint.  The DiscretePermutationInvarianceConstraint below applies to our example and removes permutation-invariant combinations of solvents that have additional dependencies as well: from baybe.constraints import (
    DiscretePermutationInvarianceConstraint,
    DiscreteDependenciesConstraint,
    ThresholdCondition,
)

DiscretePermutationInvarianceConstraint(
    parameters=[""Solvent_1"", ""Solvent_2"", ""Solvent_3""],
    # `dependencies` is optional; it is only required if some of the permutation
    # invariant entries in `parameters` have dependencies on other parameters
    dependencies=DiscreteDependenciesConstraint(
        parameters=[""Fraction_1"", ""Fraction_2"", ""Fraction_3""],
        conditions=[
            ThresholdCondition(threshold=0.0, operator="">""),
            ThresholdCondition(threshold=0.0, operator="">""),
            ThresholdCondition(threshold=0.0, operator="">""),
        ],
        affected_parameters=[[""Solvent_1""], [""Solvent_2""], [""Solvent_3""]],
    ),
)",What is the purpose of the DiscretePermutationInvarianceConstraint in the context of solvents?,It removes permutation-invariant combinations of solvents that have additional dependencies.
49,49,userguide_constraints_chunks_chunk_15,10,"# Constraints
## Discrete Constraints
### DiscreteCardinalityConstraint

Like its [continuous cousin](), the
`DiscreteCardinalityConstraint` lets you control the
number of active parameters in your design. The construction works analogously:

```python
from baybe.constraints import DiscreteCardinalityConstraint

DiscreteCardinalityConstraint(
    parameters=[""Fraction_1"", ""Fraction_2"", ""Fraction_3""],
    min_cardinality=1,  # defaults to 0
    max_cardinality=2,  # defaults to the number of affected parameters (here: 3)
)
```",What are the keywords for setting the minimum and maximum cardinality when using the `DiscreteCardinalityConstraint`?,The keywords are `min_cardinality` and `max_cardinality`.,What does the DiscreteCardinalityConstraint control in a design?,The number of active parameters.
50,50,userguide_constraints_chunks_chunk_16,10,"# Constraints
## Discrete Constraints
### DiscreteCustomConstraint

With a [`DiscreteCustomConstraint`]()
constraint, you can specify a completely custom filter:

```python
import pandas as pd
import numpy as np
from baybe.constraints import DiscreteCustomConstraint


def custom_filter(df: pd.DataFrame) -> pd.Series:  # this signature is required
    """"""
    In this example, we exclude entries where the square root of the
    temperature times the cubed pressure are larger than 5.6.
    """"""
    mask_good = np.sqrt(df[""Temperature""]) * np.power(df[""Pressure""], 3) <= 5.6

    return mask_good


DiscreteCustomConstraint(
    parameters=[  # the custom function will have access to these variables
        ""Pressure"",
        ""Temperature"",
    ],
    validator=custom_filter,
)
```

Find a detailed example [here]().

#### WARNING
Due to the arbitrary nature of code and dependencies that can be used in the
`DiscreteCustomConstraint`, (de-)serializability cannot be guaranteed. As a consequence,
using a `DiscreteCustomConstraint` results in an error if you attempt to serialize
the corresponding object or higher-level objects containing it.",Is it possible to use serialization in a use case with custom constraints?,"Due to the arbitrary nature of code and dependencies that can be used in the `DiscreteCustomConstraint`, (de-)serializability cannot be guaranteed.",What is the purpose of the `DiscreteCustomConstraint` in the provided code?,To specify a completely custom filter for data entries based on a specified condition.
51,51,userguide_constraints_chunks_chunk_3,5,"# Constraints
## Continuous Constraints

#### WARNING
Not all surrogate models are able to treat continuous constraints. In such situations
the constraints are currently silently ignored.

### ContinuousLinearConstraint

The [`ContinuousLinearConstraint`]()
asserts that the following kind of equations are true (up to numerical rounding errors):

$$

\sum_{i} x_i \cdot c_i = \text{rhs} \\
\sum_{i} x_i \cdot c_i >= \text{rhs} \\
\sum_{i} x_i \cdot c_i <= \text{rhs}
$$

where $x_i$ is the value of the $i$√¢¬Ä¬ôth parameter affected by the constraint,
$c_i$ is the coefficient for that parameter, and $\text{rhs}$ is a user-chosen number.
The (in)equality type is defined by the `operator` keyword.

As an example, let√¢¬Ä¬ôs assume we have three parameters named `x_1`, `x_2` and
`x_3`, which describe the relative concentrations in a mixture campaign.
The constraint assuring that they always sum up to 1.0 would look like this:

```python
from baybe.constraints import ContinuousLinearConstraint

ContinuousLinearConstraint(
    parameters=[""x_1"", ""x_2"", ""x_3""],  # these parameters must exist in the search space
    operator=""="",
    coefficients=[1.0, 1.0, 1.0],
    rhs=1.0,
)
```

Let us amend the example from above and assume that there is always a fourth component
to the mixture that serves as a √¢¬Ä¬úfiller√¢¬Ä¬ù. In such a case, we might want to ensure that
the first three components only make up to 80% of the mixture.
The following constraint would achieve this:

```python
from baybe.constraints import ContinuousLinearConstraint

ContinuousLinearConstraint(
    parameters=[""x_1"", ""x_2"", ""x_3""],
    operator=""<="",
    coefficients=[1.0, 1.0, 1.0],
    rhs=0.8,
)
```

A more detailed example can be found
[here]().",I feel like my constraints have been ignored. Can that happen?? ,,What does the `ContinuousLinearConstraint` assert about the equations involving parameters?,"It asserts that the sum of the parameters multiplied by their coefficients equals, is greater than, or is less than a user-chosen number (rhs), up to numerical rounding errors."
52,52,userguide_constraints_chunks_chunk_4,2,"# Constraints
## Continuous Constraints
### ContinuousCardinalityConstraint

The `ContinuousCardinalityConstraint` gives you a
tool to control the number of active factors (i.e. parameters that take a non-zero
value) in your designs. This comes handy, for example, when designing mixtures with a
limited number of components.

To create a constraint of this kind, simply specify the set of parameters on which the
constraint is to be imposed, together with the corresponding upper and lower cardinality
limits. For instance, the following constraint would ensure that there is always a
minimum of one and a maximum of two components in each parameter configuration:

```python
from baybe.constraints import ContinuousCardinalityConstraint

ContinuousCardinalityConstraint(
    parameters=[""x_1"", ""x_2"", ""x_3""],
    min_cardinality=1,  # defaults to 0
    max_cardinality=2,  # defaults to the number of affected parameters (here: 3)
    relative_threshold=0.001,  # optional, defines the range of values considered active
)
```",I want to optimize mixtures,,What is the purpose of the ContinuousCardinalityConstraint?,To control the number of active factors in designs by setting upper and lower cardinality limits.
53,53,userguide_constraints_chunks_chunk_6,7,"# Constraints
## Conditions

Conditions are elements used within discrete constraints.
While discrete constraints can operate on one or multiple parameters, a condition
always describes the relation of a single parameter to its possible values.
It is through chaining several conditions in constraints that we can build complex
logical expressions for them.
### ThresholdCondition

For numerical parameters, we might want to select a certain range, which can be
achieved with a [`ThresholdCondition`]():

```python
from baybe.constraints import ThresholdCondition

ThresholdCondition(  # will select all values above 150
    threshold=150,
    operator="">"",
)
```  ### SubSelectionCondition

In case a specific subset of values needs to be selected, it can be done with the
[`SubSelectionCondition`]():

```python
from baybe.constraints import SubSelectionCondition

SubSelectionCondition(  # will select two solvents identified by their labels
    selection=[""Ethanol"", ""DMF""]
)
```",,,What is the operator used in a ThresholdCondition to select values above 150?,""">‚Äù"
54,54,userguide_constraints_chunks_chunk_9,8,"# Constraints
## Discrete Constraints

Discrete constraints currently do not affect the optimization process directly.
Instead, they act as a filter on the search space.
For instance, a search space created via [`from_product`]()
might include invalid combinations, which can be removed again by applying constraints.

Discrete constraints have in common that they operate on one or more parameters,
identified by the `parameters` member, which expects a list of parameter names as
strings.
All of these parameters must be present in the search space specification.### DiscreteExcludeConstraint

The [`DiscreteExcludeConstraint`]()
constraint simply removes a set of search space elements, according to its
specifications.

The following example would exclude entries where √¢¬Ä¬úEthanol√¢¬Ä¬ù and √¢¬Ä¬úDMF√¢¬Ä¬ù are combined with
temperatures above 150, which might be due to their chemical instability at those
temperatures:

```python
from baybe.constraints import (
    DiscreteExcludeConstraint,
    ThresholdCondition,
    SubSelectionCondition,
)

DiscreteExcludeConstraint(
    parameters=[""Temperature"", ""Solvent""],  # names of the affected parameters
    combiner=""AND"",  # specifies how the conditions are logically combined
    conditions=[  # requires one condition for each entry in parameters
        ThresholdCondition(threshold=150, operator="">""),
        SubSelectionCondition(selection=[""Ethanol"", ""DMF""]),
    ],
)
```

A more detailed example can be found
[here]().",,,What does the `DiscreteExcludeConstraint` do in the optimization process?,It removes a set of search space elements according to its specifications.
55,55,userguide_envvars_chunks_chunk_2,2,"# Environment Variables

Several aspects of BayBE can be configured via environment variables.

## Basic Instructions

Setting an environment variable with the name `ENVVAR_NAME` is best done before calling
any Python code, and must also be done in the same session unless made persistent, e.g.
via `.bashrc` or similar:

```bash
ENVAR_NAME=""my_value""
python do_baybe_work.py
```

Or on Windows:

```shell
set ENVAR_NAME=my_value
```

Note that variables set in this manner are interpreted as text, but converted internally
to the needed format. See for instance the [`strtobool`]()
converter for values that can be set so BayBE can interpret them as Booleans.

It is also possible to set environment variables in Python:

```python
import os

os.environ[""ENVAR_NAME""] = ""my_value""

# proceed with BayBE code ...
```

However, this needs to be done carefully at the entry point of your script or session and
will not persist between sessions.",Can I use env vars?,,How can you set an environment variable in Windows for BayBE?,You can set it using the command `set ENVAR_NAME=my_value`.
56,56,userguide_envvars_chunks_chunk_3,4,"# Environment Variables
## Telemetry

Monitored quantities:

* `batch_size` used when querying recommendations
* Number of parameters in the search space
* Number of constraints in the search space
* How often [`recommend`]() was called
* How often [`add_measurements`]() was called
* How often a search space is newly created
* How often initial measurements are added before recommendations were calculated
  (√¢¬Ä¬únaked initial measurements√¢¬Ä¬ù)
* The fraction of measurements added that correspond to previous recommendations
* Each measurement is associated with a truncated hash of the user- and hostname

The following environment variables control the behavior of BayBE telemetry:

- `BAYBE_TELEMETRY_ENABLED`: Flag that can turn off telemetry entirely (default is
  `True`). To turn it off set it to `False`.
- `BAYBE_TELEMETRY_ENDPOINT`: The receiving endpoint URL for telemetry data.
- `BAYBE_TELEMETRY_VPN_CHECK`: Flag turning an initial telemetry connectivity check
  on/off (default is `True`).
- `BAYBE_TELEMETRY_VPN_CHECK_TIMEOUT`: The timeout in seconds for the check whether the
  endpoint URL is reachable.
- `BAYBE_TELEMETRY_USERNAME`: The name of the user executing BayBE code. Defaults to a
  truncated hash of the username according to the OS.
- `BAYBE_TELEMETRY_HOSTNAME`: The name of the machine executing BayBE code. Defaults to
  a truncated hash of the machine name.",Is it possible to fully enumerate a search space combinatorically?,   - `BAYBE_TELEMETRY_VPN_CHECK_TIMEOUT`: The timeout in seconds for the check whether the endpoint URL is reachable,What is the default value of `BAYBE_TELEMETRY_ENABLED`?,TRUE
57,57,userguide_envvars_chunks_chunk_4,7,"# Environment Variables
## Polars

If BayBE was installed with the additional `polars` dependency (`baybe[polars]`), it
will use the advanced methods of Polars to create the searchspace lazily and perform a
streamed evaluation of constraints. This will improve speed and memory consumption
during this process, and thus might be beneficial for very large search spaces.

Since this is still somewhat experimental, you might want to deactivate Polars without
changing the Python environment. To do so, you can set the environment variable
`BAYBE_DEACTIVATE_POLARS` to any truthy value accepted by
[`strtobool`]().:class: caution

For performance reasons, search space manipulation using `polars` is not
guaranteed to produce the same row order as the corresponding `pandas` operations.",,,How can you deactivate Polars in BayBE without changing the Python environment?,Set the environment variable `BAYBE_DEACTIVATE_POLARS` to any truthy value accepted by `strtobool`.
58,58,userguide_envvars_chunks_chunk_5,1,"# Environment Variables
## Disk Caching

For some components, such as the
[`SubstanceParameter`](), some of the
computation results are cached in local storage.

By default, BayBE determines the location of temporary files on your system and puts
cached data into a subfolder `.baybe_cache` there. If you want to change the location of
the disk cache, change:

```bash
BAYBE_CACHE_DIR=""/path/to/your/desired/cache/folder""
```

By setting

```bash
BAYBE_CACHE_DIR=""""
```

you can turn off disk caching entirely.",Where†is my cache folder?†,"
By default,†BayBE†determines the location of temporary files on your system and puts cached data into a subfolder `.baybe_cache` there. If you want tochange the location of the disk cache, change:

```bash
BAYBE_CACHE_DIR=""/path/to/your/desired/cache/folder""
```",How can you turn off disk caching in BayBE?,"By setting `BAYBE_CACHE_DIR=""""`."
59,59,userguide_envvars_chunks_chunk_6,8,"# Environment Variables
## EXPERIMENTAL: Floating Point Precision

In general, double precision is recommended because numerical stability during optimization
can be bad when single precision is used. This impacts gradient-based optimization,
i.e. search spaces with continuous parameters, more than optimization without gradients.

If you still want to use single precision, you can set the following Boolean variables:

- `BAYBE_NUMPY_USE_SINGLE_PRECISION` (defaults to `False`)
- `BAYBE_TORCH_USE_SINGLE_PRECISION` (defaults to `False`):class: warning
Currently, it cannot be guaranteed that all calculations will be performed in single precision,
even when setting the aforementioned variables. The reason is that there are several code snippets
within `BoTorch` that transform single precision variables to double precision variables.
Consequently, this feature is currently only available as an *experimental* feature.
We are however actively working on fully enabling single precision.",,,What is recommended for numerical stability during optimization?,Double precision.
60,60,userguide_getting_recommendations_chunks_chunk_2,2,"# Getting Recommendations

The core functionality of BayBE is its ability to generate context-aware recommendations
for your experiments. This page covers the basics of the corresponding user interface,
assuming that a `SearchSpace` object and optional
`Objective` and measurement objects are already in place

## The `recommend` Call

BayBE offers two entry points for requesting recommendations:

* <a id=""stateless""></a>

  **Recommenders**<br />
  \\\\
  If a single (batch) recommendation is all you need, the most direct way to interact is
  to ask one of BayBE√¢¬Ä¬ôs recommenders for it, by calling its
  `recommend()` method. To do so,
  simply pass all context information to the method call. This way, you interact with
  BayBE in a completely *stateless* way since all relevant components are explicitly
  provided at call time.

  For example, using the `BotorchRecommender`:
  ```python
  recommender = BotorchRecommender()
  recommendation = recommender.recommend(batch_size, searchspace, objective, measurements)
  ```
* <a id=""stateful""></a>

  **Campaigns**<br />
  \\\\
  By contrast, if you plan to run an extended series of experiments where you feed newly
  arriving measurements back to BayBE and ask for a refined experimental design,
  creating a `Campaign` object that tracks the experimentation
  progress is a better choice. This offers *stateful* way of interaction where
  the context is fully maintained by the campaign object:
  ```python
  recommender = BotorchRecommender()
  campaign = Campaign(searchspace, objective, recommender)
  campaign.add_measurements(measurements)
  recommendation = campaign.recommend(batch_size)
  ```",How to get my next experiment?,,What method is used to request a single batch recommendation in BayBE?,The `recommend()` method.
61,61,userguide_getting_recommendations_chunks_chunk_3,1,"# Getting Recommendations
## Excluding Configurations

When asking for recommendation, you often don√¢¬Ä¬ôt want to consider all possible
combinations of parameter values (a.k.a. the full Cartesian product space) but you may
want to exclude certain configurations that are known to be infeasible or undesirable.
There are several ways to do this, including using BayBE√¢¬Ä¬ôs sophisticated [constraint
machinery](constraints.md). Which approach is the right choice for you depends on
whether you want to exclude configurations *permanently* or (in-)activate them
*dynamically* during your experimentation cycle.",Can I put constraints on the recommendation space?†,"There are several ways to do this, including using†BayBEís†sophisticated [constraint machinery](constraints.md). Which approach is the right choice foryou depends on whether you want to exclude configurations *permanently* or (in-)activate them *dynamically* during your experimentation cycle.",What is a method to exclude certain configurations when asking for recommendations?,Using BayBE's sophisticated constraint machinery.
62,62,userguide_getting_recommendations_chunks_chunk_4,4,"# Getting Recommendations
## Excluding Configurations
### Permanent Exclusion

Permanently excluding certain parameter configurations from the recommendation is
generally done by adjusting the `SearchSpace` object
accordingly, which defines the set of candidate configurations that will be considered.

BayBE provides several ways to achieve this, which we√¢¬Ä¬ôll illustrate by comparing against
the following √¢¬Ä¬úfull√¢¬Ä¬ù search space:

```python
searchspace_full = TaskParameter(""p"", [""A"", ""B"", ""C""]).to_searchspace()
```

Depending on the specific needs and complexity of the filtering operation, one approach
may be preferred over the other, but generally these mechanisms exist:

* Restricting individual parameter objects via `active_values`:
  ```python
  searchspace_reduced = TaskParameter(
      ""p"", [""A"", ""B"", ""C""], active_values=[""A"", ""B""]
  ).to_searchspace()
  ```

  This is possible for all [label-like parameters](parameters.md#label-like). :class: caution

Note that this is *not* the same as defining the parameter with a reduced set of
values `[""A"", ""B""]` since in this case the value ""C"" would be undefined. This
makes adding measurements containing that value impossible. 
* Specifying only a subset of configurations (discrete spaces only):
  ```python
  searchspace_reduced = SearchSpace.from_dataframe(
      pd.DataFrame({""p"": [""A"", ""B""]}),
      parameters=[TaskParameter(""p"", [""A"", ""B"", ""C""])],
  )
  ```
* Filtering the search space using constraints:
  ```python
  searchspace_reduced = SearchSpace.from_product(
      parameters=[CategoricalParameter(""p"", [""A"", ""B"", ""C""])],
      constraints=[DiscreteExcludeConstraint([""p""], [SubSelectionCondition([""C""])])],
  )
  ```
* Using specialized constructors like
  `from_simplex()`.",Is it possible to restrict the search space to avoid certain combinations or parts of the space?,,How can you permanently exclude certain parameter configurations from recommendations in BayBE?,By adjusting the `SearchSpace` object accordingly.
63,63,userguide_getting_recommendations_chunks_chunk_5,Tia,"# Getting Recommendations
## Excluding Configurations
### Dynamic Exclusion

Dynamic exclusion of candidates means to in-/exclude certain parameter configurations
while you are already in the middle of your experimentation process. Here,
we need to consider two different cases:

* **Recommenders**<br />
  \\\\
  Since recommender queries are [stateless]() with respect to the
  experimental context, you can easily adjust your search space object for each query
  as needed using any of the *permanent* exclusion methods. For example:
  ```python
  # Recommendation with full search space
  searchspace_full = CategoricalParameter(""p"", [""A"", ""B"", ""C""]).to_searchspace()
  recommender.recommend(batch_size, searchspace_full, objective, measurements)

  # Recommendation with reduced search space
  searchspace_reduced = TaskParameter(
      ""p"", [""A"", ""B"", ""C""], active_values=[""A"", ""B""]
  ).to_searchspace()
  recommender.recommend(batch_size, searchspace_reduced, objective, measurements)
  ```
* **Campaigns**<br />
  \\\\
  Because the search space must be defined before a
  `Campaign` object can be created, a different approach is
  required for [stateful queries](). For this purpose,
  `Campaign`s provide a
  `toggle_discrete_candidates()` method that allows to
  dynamically enable or disable specific candidates while the campaign is running.
  The above example thus translates to:
  ```python
  campaign = Campaign(searchspace_full, objective, measurements)
  campaign.add_measurements(measurements)

  # Recommendation with full search space
  campaign.recommend(batch_size)

  # Exclude *matching* rows
  campaign.toggle_discrete_candidates(
      pd.DataFrame({""p"": [""C""]}),
      exclude=True,
  )
  # Alternatively: Exclude *non-matching* rows
  campaign.toggle_discrete_candidates(
      pd.DataFrame({""p"": [""A"", ""B""]}),
      complement=True,
      exclude=True,
  )

  # Recommend from reduced search space using altered candidate set
  campaign.recommend(batch_size)
  ```

  Note that you can alternatively toggle candidates by passing the appropriate
  `DiscreteConstraint` objects.
  For more details, see `toggle_discrete_candidates()`.:class: attention

Currently, dynamic exclusion via toggling is only possible for discrete candidates.
To restrict the set of continuous candidates, use
{class}`~baybe.constraints.base.ContinuousConstraint`s when creating the space.:class: seealso

{class}`~baybe.campaign.Campaign`s allow you to further control the candidate
generation based on the experimental trajectory taken via their `allow_*` 
{ref}`flags <userguide/campaigns:Candidate Control in Discrete Spaces>`.",Why I got error when using toggle_discrete_candidates?,pip install baybe[chem],What method do Campaign objects provide to dynamically enable or disable specific candidates while running?,`toggle_discrete_candidates()`
64,64,userguide_insights_chunks_chunk_2,2,"# Insights
In BayBE, insights provide a way of analyzing your experimental results beyond what is
required for the basic measure-recommend loop. Dependencies needed for insights are
optional and available by installing `baybe` with the respective dependency group, e.g.
via `pip install baybe[insights]`.

## Parameter Importance via SHAP

[**SH**apley **A**dditive ex**P**lanations](https://shap.readthedocs.io/en/latest/index.html)
are a popular way of interpreting models to gain insight into the importance of the
features utilized. In the context of Bayesian optimization (BO), this enables analyzing
the importance of the parameters spanning the search space. This can be useful
for identifying which parameters play a key role and which do not √¢¬Ä¬ì learnings that can
be applied in designing future campaigns. The interface is provided by the
[`SHAPInsight`]() class.",Can BayBE explain the recommendations?,,What is the method used in BayBE to analyze the importance of features in Bayesian optimization?,SHAP (SHapley Additive exPlanations).
65,65,userguide_insights_chunks_chunk_3,3,"# Insights
## Parameter Importance via SHAP
### Basic Usage

A [`SHAPInsight`]() can be obtained in several ways:

- From a [`Campaign`]() via
  [`from_campaign`]():
  ```python
  insight = SHAPInsight.from_campaign(campaign)
  ```
- From a surrogate model via [`from_surrogate`]():
  ```python
  insight = SHAPInsight.from_surrogate(surrogate, data)
  ```
- From a recommender that has an underlying surrogate model and implements
  [`get_surrogate`]()
  via [`from_recommender`]():
  ```python
  insight = SHAPInsight.from_recommender(recommender, searchspace, objective, data)
  ```

In these examples, `data` is the background data used to build the underlying explainer
model. Typically, you would set this to the measurements obtained during your
experimental campaign (for instance, [`from_campaign`]()
automatically extracts the `measurements` from the `campaign` object).",How can I compute parameter importance?,"SHAP parameter importance can be computed with the factory methods `from_campaign()`, `from_surrogate()`, and `from_recommender()` as shown below: ```python  Ö  ```",How can a SHAPInsight be obtained from a campaign?,By using the method `SHAPInsight.from_campaign(campaign)`.
66,66,userguide_insights_chunks_chunk_4,4,"# Insights
## Parameter Importance via SHAP
### Plots

After creating the insight, various methods are available to visualize the results via
the [.plot]()
interface, please refer to [available SHAP plots]().

```python
insight.plot(""bar"")
```

![SHAP_Bar_Exp_Rep](_static/insights/shap_bar_exp_rep.svg)

This result agrees well with the chemical intuition that ligands are the most important
reactants to activate the conversion, resulting in higher yields.

Such plots can also be created for data sets other than the background data that
was used to generate the insight. If this is desired, pass your data frame as second
argument:

```python
insight.plot(""beeswarm"", new_measurements)
```

![SHAP_Beeswarm_Exp_Rep](_static/insights/shap_beeswarm_exp_rep.svg)

The `force` plot type requires the user to additionally select which single data point
they want to visualize by specifying the corresponding `explanation_index`:

```python
insight.plot(
    ""force"", explanation_index=3
)  # plots the force analysis of the measurement at positional index 3
```

![SHAP_Force](_static/insights/shap_force.svg)",What explainability methods are available in bayBE?,,What type of plot requires the user to specify an explanation index to visualize a single data point?,"The ""force"" plot type."
67,67,userguide_insights_chunks_chunk_5,5,"# Insights
## Parameter Importance via SHAP
### Explainers

In general, SHAP is an exhaustive method testing all combinations of features. This
exhaustive algorithm (implemented by the [`shap.ExactExplainer`](https://shap.readthedocs.io/en/stable/generated/shap.ExactExplainer.html#shap.ExactExplainer) class) is
often not feasible in practice, and various approximate variants are available (see
[supported explainers]()). For details about their inner
mechanics, we refer to the [SHAP documentation](https://shap.readthedocs.io/en/latest/api.html#explainers).

The explainer can be changed when creating the insight:

```python
insight = SHAPInsight.from_campaign(
    campaign, explainer_cls=""KernelExplainer""
)  # default explainer
```",I want to interpret the results BayBE provided. What do I do?,,What is the default explainer used in SHAPInsight?,KernelExplainer
68,68,userguide_insights_chunks_chunk_6,6,"# Insights
## Parameter Importance via SHAP
### Experimental and Computational Representations

[`SHAPInsight`]() by default analyzes the experimental
representation of the measurements, i.e. the that specifies parameter and target values
in terms of their actual (physical) quantities. This comes with certain limitations:

A feature importance study can still be performed by looking at the computational
representation of the data points, activated by the `use_comp_rep` flag. Since all
entries in this representation are numeric by construction, there are no limitations on
the explainer type used. A study of the computational representation might also be
useful if a deeper analysis of descriptors used is of interest to the user. In general,
for each non-numerical parameter in the experimental representation, there will be
several descriptors the computational representation:

```python
insight = SHAPInsight.from_campaign(campaign, use_comp_rep=True)
insight.plot(""bar"")
```

![SHAP_Bar_Comp_Rep](_static/insights/shap_bar_comp_rep.svg)

In addition to SHAP-based explainers, we also support
[LIME](https://arxiv.org/abs/1602.04938) and
[MAPLE](https://papers.nips.cc/paper_files/paper/2018/hash/b495ce63ede0f4efc9eec62cb947c162-Abstract.html)
variants. For example:

```python
insight = SHAPInsight.from_campaign(
    campaign, explainer_cls=""LimeTabular"", use_comp_rep=True
)
insight.plot(""bar"")
```

![SHAP_Bar_Lime](_static/insights/shap_bar_lime.svg)

As expected, the result from [`LimeTabular`](https://shap.readthedocs.io/en/stable/generated/shap.explainers.other.LimeTabular.html#shap.explainers.other.LimeTabular) are very
similar to the results from the SHAP [`KernelExplainer`](https://shap.readthedocs.io/en/stable/generated/shap.KernelExplainer.html#shap.KernelExplainer) because
both methods involve linear local approximations.",,,What flag is used to activate the computational representation in SHAPInsight?,use_comp_rep
69,69,userguide_objectives_chunks_chunk_2,4,"# Objective
Optimization problems involve either a single target quantity of interest or several
(potentially conflicting) targets that need to be considered simultaneously. BayBE uses
the concept of an [`Objective`]() to allow the user to
control how these different types of scenarios are handled.

## SingleTargetObjective

The need to optimize a single [`Target`]() is the most basic
type of situation one can encounter in experimental design.
In this scenario, the fact that only one target shall be considered in the design is
communicated to BayBE by wrapping the target into a
[`SingleTargetObjective`]():

```python
from baybe.targets import NumericalTarget
from baybe.objectives import SingleTargetObjective

target = NumericalTarget(name=""Yield"", mode=""MAX"")
objective = SingleTargetObjective(target)
```

In fact, the role of the
[`SingleTargetObjective`]()
is to merely signal the absence of other [`Targets`]()
in the optimization problem.
Because this fairly trivial conversion step requires no additional user configuration,
we provide a convenience constructor for it::class: tip
* The conversion from a single [`Target`](baybe.targets.base.Target) to a [`SingleTargetObjective`](baybe.objectives.single.SingleTargetObjective) describes a one-to-one relationship and can be triggered directly from the corresponding target object:
  ```python
  objective = target.to_objective()
  ```
* Also, other class constructors that expect an  [`Objective`](baybe.objectives.base.Objective) object (such as [`Campaigns`](baybe.campaign.Campaign)) will happily accept individual [`Targets`](baybe.targets.base.Target) instead and apply the necessary
conversion behind the scenes.",No,,What is the purpose of the `SingleTargetObjective` in BayBE?,The `SingleTargetObjective` signals the absence of other targets in the optimization problem.
70,70,userguide_objectives_chunks_chunk_3,6,"# Objective
## DesirabilityObjective

The [`DesirabilityObjective`]()
enables the combination of multiple targets via scalarization into a single numerical
value (commonly referred to as the *overall desirability*), a method also utilized in
classical DOE.:class: attention
Since measurements of different targets can vary arbitrarily in scale, all targets
passed to a
[`DesirabilityObjective`](baybe.objectives.desirability.DesirabilityObjective) must be
normalizable to enable meaningful combination into desirability values. This requires
that all provided targets must have `bounds` specified (see [target user
guide](/userguide/targets.md)).
If provided, the necessary normalization is taken care of automatically. 
Otherwise, an error will be thrown.

Besides the list of [`Targets`]()
to be scalarized, this objective type takes two
additional optional parameters that let us control its behavior:

* `weights`: Specifies the relative importance of the targets in the form of a
  sequence of positive numbers, one for each target considered.<br />
  \\\\
  **Note:**
  BayBE automatically normalizes the weights, so only their relative
  scales matter.
* `scalarizer`: Specifies the [scalarization function]()
  to be used for combining the normalized target values.
  The choices are `MEAN` and `GEOM_MEAN`, referring to the arithmetic and
  geometric mean, respectively.

The definitions of the `scalarizer`s are as follows, where $\{t_i\}$ enumerate the
**normalized** target measurements of single experiment and $\{w_i\}$ are the
corresponding target weights:

$$

\text{MEAN} &= \frac{1}{\sum w_i}\sum_{i} w_i \cdot t_i \\
\text{GEOM_MEAN} &= \left( \prod_i t_i^{w_i} \right)^{1/\sum w_i}
$$

In the example below, we consider three different targets (all associated with a
different goal) and give twice as much importance to the first target relative to each
of the other two:

```python
from baybe.targets import NumericalTarget
from baybe.objectives import DesirabilityObjective

target_1 = NumericalTarget(name=""t_1"", mode=""MIN"", bounds=(0, 100))
target_2 = NumericalTarget(name=""t_2"", mode=""MIN"", bounds=(0, 100))
target_3 = NumericalTarget(name=""t_3"", mode=""MATCH"", bounds=(40, 60))
objective = DesirabilityObjective(
    targets=[target_1, target_2, target_3],
    weights=[2.0, 1.0, 1.0],  # optional (by default, all weights are equal)
    scalarizer=""GEOM_MEAN"",  # optional
)
```

For a complete example demonstrating desirability mode, see [here]().",,,What are the two available scalarization functions in the DesirabilityObjective?,MEAN and GEOM_MEAN.
71,71,userguide_objectives_chunks_chunk_4,3,"# Objective
## ParetoObjective

The [`ParetoObjective`]() can be used when the goal is to find a set of solutions that represent optimal trade-offs among multiple conflicting targets. Unlike the [`DesirabilityObjective`](), this approach does not aggregate the targets into a single scalar value but instead seeks to identify the Pareto front - the set of *non-dominated* target configurations.

Tip: A target configuration is considered non-dominated (or Pareto-optimal) if no other configuration is better in *all* targets.

Identifying the Pareto front requires maintaining explicit models for each of the targets involved. Accordingly, it requires to use acquisition functions capable of processing vector-valued input, such as `qLogNoisyExpectedHypervolumeImprovement`. This differs from the [`DesirabilityObjective`](), which relies on a single predictive model to describe the associated desirability values. However, the drawback of the latter is that the exact trade-off between the targets must be specified *in advance*, through explicit target weights. By contrast, the Pareto approach allows to specify this trade-off *after* the experiments have been carried out, giving the user the flexibly to adjust their preferences post-hoc -¬†knowing that each of the obtained
points is optimal with respect to a particular preference model.

To set up a [`ParetoObjective`](), simply specify the corresponding target objects:

```python
from baybe.targets import NumericalTarget
from baybe.objectives import ParetoObjective

target_1 = NumericalTarget(name=""t_1"", mode=""MIN"")
target_2 = NumericalTarget(name=""t_2"", mode=""MAX"")
objective = ParetoObjective(targets=[target_1, target_2])
```",What is the difference between a Pareto objective and a desirability objective?,The pareto objective does not aggregate targets into a single scalar value but instead seeks to identify the Pareto front which consists of the set of non-dominated target configurations. This means that for all points in the pareto front no other configuration is better in all targets.,What does the `ParetoObjective` aim to identify in multi-target optimization?,"The `ParetoObjective` aims to identify the Pareto front, which is the set of non-dominated target configurations."
72,72,userguide_parameters_chunks_chunk_3,6,"# Parameters

Parameters are fundamental for BayBE, as they configure the [`SearchSpace`]() and serve
as the direct link to the controllable variables in your experiment.
Before starting an iterative campaign, the user is required to specify the exact
parameters they can control and want to consider in their optimization.
note
BayBE identifies each parameter by a ``name``. All parameter names in one 
campaign must be unique.
BayBE distinguishes two parameter types, because they need to be treated very
differently under the hood: Discrete and continuous parameters.

## Continuous Parameters
### NumericalContinuousParameter

This is currently the only continuous parameter type BayBE supports.
It defines possible values from a numerical interval called
`bounds`, and thus has an infinite amount of possibilities.
Unless restrained by [`Constraint`]()s, BayBE will consider any possible parameter value
that lies within the chosen interval.

```python
from baybe.parameters import NumericalContinuousParameter

NumericalContinuousParameter(
    name=""Temperature"",
    bounds=(0, 100),
)
```",,,What is the only continuous parameter type supported by BayBE?,NumericalContinuousParameter
73,73,userguide_parameters_chunks_chunk_5,5,"# Parameters
## Discrete Parameters
A discrete parameter has a finite set of possible values that can be recommended.
These values can be numeric or label-like (i.e. strings) and are transformed
internally before being ingested by the surrogate model.

### NumericalDiscreteParameter

This is the right type for parameters that have numerical values.
We support sets with equidistant values like `(1, 2, 3, 4, 5)` but also unevenly
spaced sets of numbers like `(0.2, 1.0, 2.0, 5.0, 10.0, 50.0)`.

```python
from baybe.parameters import NumericalDiscreteParameter

NumericalDiscreteParameter(
    name=""Temperature"",
    # you can also use np.arange or similar to provide values
    values=(0, 10, 20, 30, 40, 50),
)
```",Which parameter type do I use if I allow my†variables to have discrete and numerical values?,,What is an example of a numerical discrete parameter in the provided context?,"Temperature with values (0, 10, 20, 30, 40, 50)."
74,74,userguide_parameters_chunks_chunk_6,7,"# Parameters
## Discrete Parameters
### CategoricalParameter

A [`CategoricalParameter`]() supports sets of strings as labels.
This is most suitable if the experimental choices cannot easily be translated into a
number.
Examples for this could be vendors like `(""Vendor A"", ""Vendor B"", ""Vendor C"")` or
post codes like `(""PO16 7GZ"", ""GU16 7HF"", ""L1 8JQ"")`.

Categorical parameters in BayBE can be encoded via integer or one-hot encoding.
For some cases, such basic forms of encoding make sense, e.g. if we had a parameter
for a setting with values
`(""low"", ""medium"", ""high"")`, an integer-encoding into values `(1, 2, 3)` would
be reasonable.

```python
from baybe.parameters import CategoricalParameter

CategoricalParameter(
    name=""Intensity"",
    values=(""low"", ""medium"", ""high""),
    active_values=(
        ""low"",  # optional, only combinations with Intensity=low will be recommended
    ),
    encoding=""INT"",  # optional, uses integer encoding as described above
)
```

However, in other cases, these encodings would introduce undesired biases to the model.
Take, for instance, a parameter for a choice of solvents with values
`(""Solvent A"", ""Solvent B"", ""Solvent C"")`. Encoding these with `(1, 2, 3)` as
above would imply that √¢¬Ä¬úSolvent A√¢¬Ä¬ù is more similar to √¢¬Ä¬úSolvent B√¢¬Ä¬ù than to √¢¬Ä¬úSolvent C√¢¬Ä¬ù,
simply because the number 1 is closer to 2 than to 3.
Hence, for an arbitrary set of labels, such an ordering cannot generally be assumed.
In the particular case of substances, it not even possible to describe the similarity
between labels by ordering along one single dimension.
For this reason, we also provide the [`SubstanceParameter`](), which encodes labels
corresponding to small molecules with chemical descriptors, capturing their similarities
much better and without the need for the user to think about ordering and similarity
in the first place.
This concept is generalized in the [`CustomDiscreteParameter`](), where the user can
provide their own custom set of descriptors for each label.",,,What type of parameter supports sets of strings as labels in BayBE?,CategoricalParameter
75,75,userguide_parameters_chunks_chunk_7,Tia,"# Parameters
## Discrete Parameters
### SubstanceParameter

Instead of `values`, this parameter accepts `data` in form of a dictionary. The
items correspond to pairs of labels and [SMILES](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system).
SMILES are string-based representations of molecular structures.
Based on these, BayBE can assign each label a set of molecular descriptors as encoding.

For instance, a parameter corresponding to a choice of solvents can be initialized with:

```python
from baybe.parameters import SubstanceParameter

SubstanceParameter(
    name=""Solvent"",
    data={
        ""Water"": ""O"",
        ""1-Octanol"": ""CCCCCCCCO"",
        ""Toluene"": ""CC1=CC=CC=C1"",
    },
    active_values=[  # optional, recommends only water and toluene as solvent
        ""Water"",
        ""Toluene"",
    ],
    encoding=""MORDRED"",  # optional
    decorrelate=0.7,  # optional
)
```

The `encoding` defines what kind of descriptors are calculated using the
[scikit-fingerprints](https://scikit-fingerprints.github.io/scikit-fingerprints/) package.
It can be specified either by passing the corresponding [`SubstanceEncoding`]() member
(click to see full list of options) or its string representation, e.g. use
[`SubstanceParameter.MORDRED`]()
or its string alias `""MORDRED""` to select the `MordredFingerprint`.

Here are examples of a few popular fingerprints:

* `ECFP`: Extended Connectivity FingerPrint,
  which is a circular topological fingerprint similar to Morgan fingerprint.
* `MORDRED`: Chemical descriptor based fingerprint.
* `RDKIT`: The RDKit fingerprint, which is based on hashing of molecular subgraphs.

You can customize the fingerprint computation by passing arguments of the corresponding
[scikit-fingerprints](https://scikit-fingerprints.github.io/scikit-fingerprints/) class to the `kwargs_fingerprint` argument the [`SubstanceParameter`]() constructor.
Similarly, for fingerprints requiring conformers,
the configuration options for conformer computation can be specified via `kwargs_conformer`.

```python
from baybe.parameters import SubstanceParameter

SubstanceParameter(
    name=""Solvent"",
    data={
        ""Water"": ""O"",
        ""1-Octanol"": ""CCCCCCCCO"",
        ""Toluene"": ""CC1=CC=CC=C1"",
    },
    encoding=""ECFP"",
    kwargs_fingerprint={
        ""radius"": 4,  # Set maximum radius of resulting subgraphs
        ""fp_size"": 1024,  # Change the number of computed bits
    },
)

```

These calculations will typically result in 500 to 1500 numbers per molecule.
To avoid detrimental effects on the surrogate model fit, we reduce the number of
descriptors via decorrelation before using them.
For instance, the `decorrelate` option in the example above specifies that only
descriptors with a correlation lower than 0.7 to any other descriptor will be kept.
This usually reduces the number of descriptors to 10-50, depending on the specific
items in `data`.

#### WARNING
The descriptors calculated for a [`SubstanceParameter`]() were developed to describe
small molecules and are not suitable for other substances. If you deal with large
molecules like polymers or arbitrary substance mixtures, we recommend to provide your
own descriptors via the [`CustomDiscreteParameter`]().

:class: note
The ``SubstanceParameter`` is only available if BayBE was installed with the 
additional ``chem`` dependency.",How to create chemical SubstanceParameter? ,"from baybe.parameters import SubstanceParameter

SubstanceParameter(
    name=""Solvent"",
    data={
        ""Water"": ""O"",
        ""1-Octanol"": ""CCCCCCCCO"",
        ""Toluene"": ""CC1=CC=CC=C1"",
    },
    active_values=[  # optional, recommends only water and toluene as solvent
        ""Water"",
        ""Toluene"",
    ],
    encoding=""MORDRED"",  # optional
    decorrelate=0.7,  # optional
)",What type of data does the SubstanceParameter accept?,A dictionary in the form of pairs of labels and SMILES.
76,76,userguide_parameters_chunks_chunk_8,8,"# Parameters
## Discrete Parameters
### CustomDiscreteParameter

The `encoding` concept introduced above is generalized by the
[`CustomDiscreteParameter`]().
Here, the user is expected to provide their own descriptors for the encoding.

Take, for instance, a parameter that corresponds to the choice of a polymer.
Polymers are not well represented by the small molecule descriptors utilized in the
[`SubstanceParameter`]().
Still, one could provide experimental measurements or common metrics used to classify
polymers:

```python
import pandas as pd
from baybe.parameters import CustomDiscreteParameter

descriptors = pd.DataFrame(
    {
        ""Glass_Transition_TempC"": [20, -71, -39],
        ""Weight_kDalton"": [120, 32, 241],
    },
    index=[""Polymer A"", ""Polymer B"", ""Polymer C""],  # put labels in the index
)

CustomDiscreteParameter(
    name=""Polymer"",
    data=descriptors,
    active_values=(  # optional, enforces that only Polymer A or C is recommended
        ""Polymer A"",
        ""Polymer C"",
    ),
    decorrelate=True,  # optional, uses default correlation threshold
)
```

With the [`CustomDiscreteParameter`](), you can also encode parameter labels that have
nothing to do with substances.
For example, a parameter corresponding to the choice of a vendor is typically not
easily encoded with standard means.
In BayBE√¢¬Ä¬ôs framework, you can provide numbers corresponding e.g. to delivery time,
reliability or average price of the vendor to encode the labels via the
[`CustomDiscreteParameter`]().",,,What is the purpose of the `CustomDiscreteParameter` in BayBE's framework?,"The `CustomDiscreteParameter` allows users to provide their own descriptors for encoding parameters that are not well represented by standard means, such as polymer choices or vendor selection."
77,77,userguide_parameters_chunks_chunk_9,9,"# Parameters
## Discrete Parameters
### TaskParameter

Often, several experimental campaigns involve similar or even identical parameters but
still have one or more differences.
For example, when optimizing reagents in a chemical reaction, the reactants remain
constant, so they are not parameters.
Similarly, in a mixture development for cell culture media, the cell type is fixed and
hence not a parameter.
However, once we plan to mix data from several campaigns, both reactants and cell
lines can also be considered parameters in that they encode the necessary context.
BayBE is able to process such context information with the [`TaskParameter`]().
In many cases, this can drastically increase the optimization performance due to the
enlarged data corpus.

#### SEE ALSO
For details, refer to [transfer learning](transfer_learning.md).",What do I do if I have parameters which were constant but are now subject to change when I add more data?,,What is the purpose of the `TaskParameter` in BayBE?,"The `TaskParameter` is used to process context information, which can drastically increase optimization performance by enlarging the data corpus."
78,78,userguide_recommenders_chunks_chunk_3,3,"# Recommenders

## General Information

Recommenders are an essential part of BayBE that effectively explore the search space
and provide recommendations for the next experiment or batch of experiments.
Available recommenders can be partitioned into the following subclasses.

## Pure Recommenders

Pure recommenders simply take on the task to recommend measurements. They each contain
the inner logic to do so via different algorithms and approaches.
While some pure recommenders are versatile and work across different types of search
spaces, other are specifically designed for discrete or continuous spaces. The
compatibility is indicated via the corresponding `compatibility` class variable.",What is a recommender?,Recommenders explore the search space and provide recommendations for the next experiment or batch.,What are the two types of recommenders mentioned in the document?,Pure recommenders and other subclasses of recommenders.
79,79,userguide_recommenders_chunks_chunk_4,5,"# Recommenders
## Pure Recommenders
### Bayesian Recommenders

The Bayesian recommenders in BayBE are built on the foundation of the
[`BayesianRecommender`]()
class, offering an array of possibilities with internal surrogate models and support
for various acquisition functions.

* The **[`BotorchRecommender`]()**
  is a powerful recommender based on BoTorch√¢¬Ä¬ôs optimization engine that can be applied
  to all kinds of search spaces. In continuous spaces, its `sequential_continuous` flag
  allows to choose between greedy sequential optimization and batch optimization as the
  underlying point generation mode. In discrete/hybrid spaces, sequential greedy
  selection is the only available mode and is thus activated automatically.

  Note that the recommender performs a brute-force search when applied to hybrid search
  spaces, as it does gradient-based optimization in the continuous part of the space
  while exhaustively evaluating configurations of the discrete subspace. You can customize this
  behavior to only sample a certain percentage of the discrete subspace via the
  `sampling_percentage`
  argument and to choose different sampling algorithms via the
  `hybrid_sampler`
  argument.

  The gradient-based optimization part can also further be controlled by the
  `n_restarts` and
  `n_raw_samples`
  arguments. For details, please refer
  to [BotorchRecommender]().
* The **[`NaiveHybridSpaceRecommender`]()**
  can be applied to all search spaces, but is intended to be used in hybrid spaces.
  This recommender combines individual recommenders for the continuous and the discrete
  subspaces. It independently optimizes each subspace and consolidates the best results
  to generate a candidate for the original hybrid space.",My optimization is too slow. How can I speed up?,,What is the name of the recommender based on BoTorch‚Äôs optimization engine?,BotorchRecommender
80,80,userguide_recommenders_chunks_chunk_5,6,"# Recommenders
## Pure Recommenders
### Clustering Recommenders

BayBE offers a set of recommenders leveraging techniques to facilitate point selection
via clustering:

* **[`PAMClusteringRecommender`]():**
  This recommender utilizes partitioning around medoids.
* **[`KMeansClusteringRecommender`]():**
  This recommender implements k-means clustering.
* **[`GaussianMixtureClusteringRecommender`]():**
  This recommender leverages Gaussian Mixture Models for clustering.",,,What clustering technique does PAMClusteringRecommender use?,Partitioning around medoids.
81,81,userguide_recommenders_chunks_chunk_6,7,"# Recommenders
## Pure Recommenders
### Sampling Recommenders

BayBE provides two recommenders that recommend by sampling form the search space:

* **[`RandomRecommender`]():**
  This recommender offers random recommendations for all types of search spaces.
  It is extensively used in backtesting examples, providing a valuable comparison.

* **[`FPSRecommender`]():**
  This recommender is only applicable for discrete search spaces, and recommends points
  based on farthest point sampling.",,,What type of search spaces does the FPSRecommender operate on?,Discrete search spaces.
82,82,userguide_recommenders_chunks_chunk_7,8,"# Recommenders
## Meta Recommenders

In analogy to meta studies, meta recommenders are wrappers that operate on a sequence
of pure recommenders and determine when to switch between them according to different
logics. BayBE offers three distinct kinds of meta recommenders.

* The
  [`TwoPhaseMetaRecommender`]()
  employs two distinct recommenders and switches between them at a certain specified
  point, controlled by the `switch_after` attribute. This is useful e.g. if you want a
  different recommender for the initial recommendation when there is no data yet
  available. This simple example would recommend randomly for the first batch and switch
  to a Bayesian recommender as soon as measurements have been ingested:

```python
from baybe.recommenders import (
    BotorchRecommender,
    TwoPhaseMetaRecommender,
    RandomRecommender,
)

recommender = TwoPhaseMetaRecommender(
    initial_recommender=RandomRecommender(), recommender=BotorchRecommender()
)
```

* The **[`SequentialMetaRecommender`]()**
  introduces a simple yet versatile approach by utilizing a predefined list of
  recommenders. By specifying the desired behavior using the `mode` attribute, it is
  possible to flexibly determine the meta recommender√¢¬Ä¬ôs response when it exhausts the
  available recommenders. The possible choices are to either raise an error, re-use the
  last recommender or re-start at the beginning of the sequence.
* Similar to the `SequentialMetaRecommender`, the
  **[`StreamingSequentialMetaRecommender`]()**
  enables the utilization of *arbitrary* iterables to select recommender.

  #### WARNING
  Due to the arbitrary nature of iterables that can be used, (de-)serializability cannot
  be guaranteed. As a consequence, using a `StreamingSequentialMetaRecommender` results
  in an error if you attempt to serialize the corresponding object or higher-level
  objects containing it.",,,What is the purpose of the `TwoPhaseMetaRecommender` in BayBE?,It employs two distinct recommenders and switches between them at a specified point controlled by the `switch_after` attribute.
83,83,userguide_searchspace_chunks_chunk_1,3,"# Search Spaces

The term √¢¬Ä¬úsearch space√¢¬Ä¬ù refers to the domain of possible values for the parameters that are being optimized during a campaign. A search space represents the space within which BayBE explores and searches for the optimal solution. It is implemented via the [`SearchSpace`]() class.

Note that a search space is not necessarily equal to the space of allowed measurements. That is, if configured properly, it is possible to add measurements to a campaign that are not part of the search space. For instance, a numerical parameter with values `1.0`, `2.0`, `5.0` will create a searchspace with these numbers, but you can also add measurements where the parameter has a value of e.g. `2.12`.

In BayBE, a search space is a union of two (potentially empty) subspaces. The [`SubspaceDiscrete`]() contains all discrete parameters, while the [`SubspaceContinuous`]() contains all continuous parameters.

Depending on which of the subspaces are non-empty, a `SearchSpace` has exactly one of the three [`SearchSpaceType`]()√¢¬Ä¬ôs:

| `SubspaceDiscrete`   | `SubspaceContinuous`   | [`SearchSpaceType`]()            |
|----------------------|------------------------|----------------------------------|
| Non-empty            | Empty                  | [`SearchSpaceType.DISCRETE`]()   |
| Empty                | Non-Empty              | [`SearchSpaceType.CONTINUOUS`]() |
| Non-Empty            | Non-empty              | [`SearchSpaceType.HYBRID`]()     |","Can you explain search space, subspace and search space type?","The `SearchSpace` contains all possible values of all parameters of the optimization campaign. It consists of two, potentially empty subspaces: One for the discrete (`SubspaceDiscrete`) and one for the continuous (`SubspaceContinuous`) parameters. Depending on which of them is empty, the `SearchSpaceType` is either `DISCRETE`, `CONTINUOUS`, or `HYBRID` (in case both are on-empty).",What class implements the search space in BayBE?,The `SearchSpace` class.
84,84,userguide_searchspace_chunks_chunk_11,6,"# Search Spaces
## Constructing Full Search Spaces

There are several methods available for creating full search spaces.
### From the Default Constructor

It is possible to construct a search space by simply using the default constructor of the `SearchSpace` class.
The required parameters are derived from the `__init__` function of that class.
In the simplest setting, it is sufficient to provide a single subspace for creating either a discrete or continuous search, or provide two subspaces for creating a hybrid search space.

```python
searchspace = SearchSpace(discrete=discrete_subspace, continuous=continuous_subspace)
```

While this constructor is the default choice, it might not be the most convenient.
Consequently, other constructors are available.### Building from the Product of Parameter Values

The function [`SearchSpace.from_product`]() is analog to the corresponding function available for `SubspaceDiscrete`, but allows the parameter list to contain both discrete and continuous parameters.",,,How can a search space be constructed using the `SearchSpace` class?,"A search space can be constructed by using the default constructor of the `SearchSpace` class, providing either a single subspace for discrete or continuous search, or two subspaces for a hybrid search space."
85,85,userguide_searchspace_chunks_chunk_13,,"# Search Spaces
## Constructing Full Search Spaces
### Constructing from a Dataframe

[`SearchSpace.from_dataframe`]() constructs a search space from a given dataframe.
Due to the ambiguity between discrete and continuous parameter representations when identifying parameter ranges based only on data, this function requires that the appropriate parameter definitions be explicitly provided. This is different for its subspace counterparts [`SubspaceDiscrete.from_dataframe`]() and [`SubspaceContinuous.from_dataframe`](), where a fallback mechanism can automatically infer minimal parameter specifications if omitted.

```python
from baybe.searchspace import SearchSpace

p_cont = NumericalContinuousParameter(name=""c"", bounds=[0, 1])
p_disc = NumericalDiscreteParameter(name=""d"", values=[1, 2, 3])
df = pd.DataFrame({""c"": [0.3, 0.7], ""d"": [2, 3]})
searchspace = SearchSpace.from_dataframe(df=df, parameters=[p_cont, p_disc])
print(searchspace)
```

```default
SearchSpace
   Search Space Type: HYBRID
   SubspaceDiscrete
      Discrete Parameters
           Name                        Type  Num_Values Encoding
         0    d  NumericalDiscreteParameter           3     None
      Experimental Representation
            d
         0  2
         1  3
      Constraints
         Empty DataFrame
         Columns: []
         Index: []
      Computational Representation
            d
         0  2
         1  3
   SubspaceContinuous
      Continuous Parameters
           Name                          Type  Lower_Bound  Upper_Bound
         0    c  NumericalContinuousParameter          0.0          1.0
      Linear Equality Constraints
         Empty DataFrame
         Columns: []
         Index: []
      Linear Inequality Constraints
         Empty DataFrame
         Columns: []
         Index: []
      Non-linear Constraints
         Empty DataFrame
         Columns: []
         Index: []
```",Can I create a search space from a dataframe with continuous and discrete data?,"SearchSpace.from_dataframe constructs a search space from a given dataframe. Due to the ambiguity between discrete and continuous parameter representations when identifying parameter ranges based only on data, this function requires that the appropriate parameter definitions be explicitly provided. This is different for its subspace counterparts SubspaceDiscrete.from_dataframe and SubspaceContinuous.from_dataframe, where a fallback mechanism can automatically infer minimal parameter specifications if omitted.from baybe.searchspace import SearchSpace

p_cont = NumericalContinuousParameter(name=""c"", bounds=[0, 1])
p_disc = NumericalDiscreteParameter(name=""d"", values=[1, 2, 3])
df = pd.DataFrame({""c"": [0.3, 0.7], ""d"": [2, 3]})
searchspace = SearchSpace.from_dataframe(df=df, parameters=[p_cont, p_disc])
print(searchspace)",What method constructs a search space from a given dataframe in the context provided?,SearchSpace.from_dataframe
86,86,userguide_searchspace_chunks_chunk_14,7,"# Search Spaces
## Restricting Search Spaces Using Constraints

Most constructors for both subspaces and search spaces support the optional keyword argument `constraints` to provide a list of [`Constraint`]() objects.
When constructing full search spaces, the type of each constraint is checked, and the consequently applied to the corresponding subspace.

```python
constraints = [...]
# Using one example constructor here
searchspace = SearchSpace.from_product(parameters=parameters, constraints=constraints)
```

",,,What keyword argument is optional when constructing subspaces and search spaces?,constraints
87,87,userguide_searchspace_chunks_chunk_3,4,"# Search Spaces
## Discrete Subspaces
The `SubspaceDiscrete` contains all the discrete parameters of a `SearchSpace`. There are different ways of constructing this subspace.

### Building from the Product of Parameter Values

The method [`SearchSpace.from_product`]() constructs the full cartesian product of the provided parameters:

```python
from baybe.parameters import NumericalDiscreteParameter, CategoricalParameter
from baybe.searchspace import SubspaceDiscrete

parameters = [
    NumericalDiscreteParameter(name=""x0"", values=[1, 2, 3]),
    NumericalDiscreteParameter(name=""x1"", values=[4, 5, 6]),
    CategoricalParameter(name=""Speed"", values=[""slow"", ""normal"", ""fast""]),
]
subspace = SubspaceDiscrete.from_product(parameters=parameters)
```

In this example, `subspace` has a total of 27 different parameter configuration.

```default
      x0   x1   Speed
 0   1.0  4.0    slow
 1   1.0  4.0  normal
 2   1.0  4.0    fast
 ..  ...  ...     ...
 24  3.0  6.0    slow
 25  3.0  6.0  normal
 26  3.0  6.0    fast

  [27 rows x 3 columns]
```",Is it possible to fully enumerate a search space combinatorically?,yes,How many different parameter configurations are in the `SubspaceDiscrete` created from the provided parameters?,27
88,88,userguide_searchspace_chunks_chunk_4,8,"# Search Spaces
## Discrete Subspaces
### Constructing from a Dataframe

[`SubspaceDiscrete.from_dataframe`]() constructs a discrete subspace from a given dataframe.
By default, this method tries to infer the data column as as a [`NumericalDiscreteParameter`]() and uses [`CategoricalParameter`]() as fallback.
However, it is possible to change this behavior by using the optional `parameters` keyword.
This list informs `from_dataframe` about the parameters and the types of parameters that should be used.
In particular, it is necessary to provide such a list if there are non-numerical parameters that should not be interpreted as categorical parameters.

```python
import pandas as pd

df = pd.DataFrame(
    {
        ""x0"": [2, 3, 3],
        ""x1"": [5, 4, 6],
        ""x2"": [9, 7, 9],
    }
)
subspace = SubspaceDiscrete.from_dataframe(df)
```

```default
 Discrete Parameters
   Name                        Type  Num_Values Encoding
 0   x0  NumericalDiscreteParameter           2     None
 1   x1  NumericalDiscreteParameter           3     None
 2   x2  NumericalDiscreteParameter           2     None
```",,,What method constructs a discrete subspace from a given dataframe?,`SubspaceDiscrete.from_dataframe`
89,89,userguide_searchspace_chunks_chunk_5,9,"# Search Spaces
## Discrete Subspaces
### Creating a Simplex-Bound Discrete Subspace

[`SubspaceDiscrete.from_simplex`]() can be used to efficiently create a discrete search space (or discrete subspace) that is restricted by a simplex constraint, limiting the maximum sum of the parameters per dimension.
This method uses a shortcut that removes invalid candidates already during the creation of parameter combinations and avoids to first create the full product space before filtering it.

In the following example, a naive construction of the subspace would first construct the full product space, containing 25 points, although only 15 points are actually part of the simplex.

```python
parameters = [
    NumericalDiscreteParameter(name=""p1"", values=[0, 0.25, 0.5, 0.75, 1]),
    NumericalDiscreteParameter(name=""p2"", values=[0, 0.25, 0.5, 0.75, 1]),
]
subspace = SubspaceDiscrete.from_simplex(max_sum=1.0, simplex_parameters=parameters)
```

```default
       p1    p2
 0   0.00  0.00
 1   0.00  0.25
 2   0.00  0.50
 ..   ...   ...
 12  0.75  0.00
 13  0.75  0.25
 14  1.00  0.00

 [15 rows x 2 columns]
```

Note that it is also possible to provide additional parameters that then enter in the form of a Cartesian product.
These can be provided via the keyword `product_parameters`.
",How can I create a discrete search space?,,How many points are part of the simplex when using the `SubspaceDiscrete.from_simplex` method with a maximum sum of 1.0 for two parameters?,15 points.
90,90,userguide_searchspace_chunks_chunk_6,10,"# Search Spaces
## Discrete Subspaces
### Representation of Data within Discrete Subspaces

Internally, discrete subspaces are represented by two dataframes, the *experimental* and the *computational* representation.

The experimental representation (`exp_rep`) contains all parameters as they were provided upon the construction of the search space and viewed by the experimenter. The computational representation (`comp_rep`) contains a representation of parameters that is actually used for the internal calculation.

In particular, the computational representation contains no more labels or constant columns. This happens e.g. for [`SubstanceParameter`]() or [`CategoricalParameter`](). Further, note that the shape of the computational representation can also change depending on the chosen encoding.

The following example demonstrates the difference:

```python
from baybe.parameters import NumericalDiscreteParameter, CategoricalParameter

speed = CategoricalParameter(""Speed"", values=[""slow"", ""normal"", ""fast""], encoding=""OHE"")
temperature = NumericalDiscreteParameter(name=""Temperature"", values=[90, 105])

subspace = SubspaceDiscrete.from_product(parameters=[speed, temperature])
```

```default
  Experimental Representation
      Speed  Temperature
  0    slow         90.0
  1    slow        105.0
  2  normal         90.0
  3  normal        105.0
  4    fast         90.0
  5    fast        105.0

  Computational Representation
     Speed_slow  Speed_normal  Speed_fast  Temperature
  0           1             0           0         90.0
  1           1             0           0        105.0
  2           0             1           0         90.0
  3           0             1           0        105.0
  4           0             0           1         90.0
  5           0             0           1        105.0
```",How is the data contained in a searchspace being represented and handled internally?,"Internally, the data is represented by the so-called ìcomputational representationî",What are the two types of representations used for discrete subspaces?,Experimental representation and computational representation.
91,91,userguide_searchspace_chunks_chunk_8,10,"# Search Spaces
## Continuous Subspaces

The `SubspaceContinuous` contains all the continuous parameters of a `SearchSpace`. There are different ways of constructing this subspace.

### Using Explicit Bounds

The [`SubspaceContinuous.from_bounds`]() method can be used to easily create a subspace representing a hyperrectangle.

```python
from baybe.searchspace import SubspaceContinuous

bounds = pd.DataFrame({""param1"": [0, 1], ""param2"": [-1, 1]})
subspace = continuous = SubspaceContinuous.from_bounds(bounds)
```

```default
 Continuous Parameters
      Name                          Type  Lower_Bound  Upper_Bound
 0  param1  NumericalContinuousParameter          0.0          1.0
 1  param2  NumericalContinuousParameter         -1.0          1.0
```",How can I create a subspace representing a hyperrectangle?,The [`SubspaceContinuous.from_bounds`]() method can be used to easily create a subspace representing a hyperrectangle.,What method is used to create a continuous subspace representing a hyperrectangle in the `SubspaceContinuous` class?,The `SubspaceContinuous.from_bounds` method.
92,92,userguide_searchspace_chunks_chunk_9,,"# Search Spaces
## Continuous Subspaces
### Constructing from a Dataframe

Similar to discrete subspaces, continuous spaces can also be constructed using [`SubspaceContinuous.from_dataframe`]().
However, when using this method to create a continuous space, it will create the smallest axis-aligned hyperrectangle-shaped continuous subspace that contains the points specified in the given dataframe.

```python
from baybe.parameters import NumericalContinuousParameter
from baybe.searchspace.continuous import SubspaceContinuous

points = pd.DataFrame(
    {
        ""param1"": [0, 1, 2],
        ""param2"": [-1, 0, 1],
    }
)
subspace = SubspaceContinuous.from_dataframe(df=points)
```

As for discrete subspaces, this method automatically infers the parameter types but can be provided with an optional list `parameters`.

```default
 Continuous Parameters
      Name                          Type  Lower_Bound  Upper_Bound
 0  param1  NumericalContinuousParameter          0.0          2.0
 1  param2  NumericalContinuousParameter         -1.0          1.0
```",How to create a search space from a continuous data?,"continuous spaces can be constructed using [`SubspaceContinuous.from_dataframe`]().
However, when using this method to create a continuous space, it will create the smallest axis-aligned hyperrectangle-shaped continuous subspace that contains the points specified in the given dataframe.

```python
from baybe.parameters import NumericalContinuousParameter
from baybe.searchspace.continuous import SubspaceContinuous

points = pd.DataFrame(
    {
        ""param1"": [0, 1, 2],
        ""param2"": [-1, 0, 1],
    }
)
subspace = SubspaceContinuous.from_dataframe(df=points)
```

As for discrete subspaces, this method automatically infers the parameter types but can be provided with an optional list `parameters`.

```default
 Continuous Parameters
      Name                          Type  Lower_Bound  Upper_Bound
 0  param1  NumericalContinuousParameter          0.0          2.0
 1  param2  NumericalContinuousParameter         -1.0          1.0
```",What method is used to create a continuous subspace from a dataframe in the provided context?,SubspaceContinuous.from_dataframe()
93,93,userguide_serialization_chunks_chunk_10,7,"# Serialization
## Deserialization from configuration strings
### Invoking alternative constructors

Many BayBE classes offer additional routes of construction next to the default
mechanism via the class√¢¬Ä¬ô `__init__` method.
This offers convenient ways of object initialization alternative to specifying
an object√¢¬Ä¬ôs attributes in their √¢¬Ä¬úcanonical√¢¬Ä¬ù form, which is often not the preferred
approach.

For instance, a search space is composed of two sub-components, a
[discrete subspace]()
and a [continuous subspace](),
which are accordingly expected by the
[`SearchSpace`]() constructor.
However, instead of providing the two components directly, most users would more
naturally invoke one of the alternative class methods available, such as
`SearchSpace.from_product` or
`SearchSpace.from_dataframe`.

Using a serialization string, the same alternative routes can be triggered via the
optional `constructor` field that allows specifying the initializer to be used for the
object creation step:

```python
from baybe.searchspace import SearchSpace
from baybe.parameters import CategoricalParameter, NumericalDiscreteParameter

searchspace = SearchSpace.from_product(
    parameters=[
        CategoricalParameter(name=""Category"", values=[""low"", ""high""]),
        NumericalDiscreteParameter(name=""Number"", values=[1, 2, 3]),
    ]
)

searchspace_json = """"""
{
    ""constructor"": ""from_product"",
    ""parameters"": [
        {
            ""type"": ""CategoricalParameter"",
            ""name"": ""Category"",
            ""values"": [""low"", ""high""]
        },
        {
            ""type"": ""NumericalDiscreteParameter"",
            ""name"": ""Number"",
            ""values"": [1, 2, 3]
        }
    ]
}
""""""

assert searchspace == SearchSpace.from_json(searchspace_json)
```",,,What are the two alternative constructors for the `SearchSpace` class mentioned in the context?,`SearchSpace.from_product` and `SearchSpace.from_dataframe`.
94,94,userguide_serialization_chunks_chunk_11,,"# Serialization
## Deserialization from configuration strings
### Dataframe deserialization

When serializing BayBE objects, contained [`DataFrames`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame) are
automatically converted to a binary format in order to

1. ensure that the involved data types are exactly restored after completing the roundtrip and
2. decrease the size of the serialization string through compression.

From the user√¢¬Ä¬ôs perspective, this has the disadvantage that the resulting JSON
representation is not human-readable, which can be a challenge when working
with configuration strings.

While you can manually work around this additional conversion step using our
`serialize_dataframe` and
`deserialize_dataframe` helpers,
a more elegant solution becomes apparent when noticing that [invoking alternative
constructors](#alternative-constructors) also works for non-BayBE objects.
In particular, this means you can resort to any dataframe constructor of your choice
(such as [`DataFrame.from_records`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_records.html#pandas.DataFrame.from_records))
when defining your configuration, instead of having to work with compressed formats:

```python
import pandas as pd
from baybe.searchspace.discrete import SubspaceDiscrete

subspace = SubspaceDiscrete.from_dataframe(
    pd.DataFrame.from_records(
        data=[[1, ""a""], [2, ""b""], [3, ""c""]], columns=[""Number"", ""Category""]
    )
)

subspace_json = """"""
{
    ""constructor"": ""from_dataframe"",
    ""df"": {
        ""constructor"": ""from_records"",
        ""data"": [[1, ""a""], [2, ""b""], [3, ""c""]],
        ""columns"": [""Number"", ""Category""]
    }
}
""""""
reconstructed = SubspaceDiscrete.from_json(subspace_json)

assert subspace == reconstructed
```",My DataFrame is serialized to JSON that I don't understand. How can I read it and edit it?,"Yes, BayBE serializes DataFrames to a compressed binary format, which makes the JSON unreadable. This is intentional ¬ó it helps preserve exact data types and reduces size.

But if you want to read and edit the JSON yourself, you can resort to any dataframe constructor of your choice
(such as [`DataFrame.from_records`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_records.html#pandas.DataFrame.from_records))
when defining your configuration, instead of having to work with compressed formats:

```python
import pandas as pd
from baybe.searchspace.discrete import SubspaceDiscrete

subspace = SubspaceDiscrete.from_dataframe(
    pd.DataFrame.from_records(
        data=[[1, ""a""], [2, ""b""], [3, ""c""]], columns=[""Number"", ""Category""]
    )
)

subspace_json = """"""
{
    ""constructor"": ""from_dataframe"",
    ""df"": {
        ""constructor"": ""from_records"",
        ""data"": [[1, ""a""], [2, ""b""], [3, ""c""]],
        ""columns"": [""Number"", ""Category""]
    }
}
""""""
reconstructed = SubspaceDiscrete.from_json(subspace_json)

assert subspace == reconstructed
```",What is the purpose of converting DataFrames to a binary format during serialization in BayBE objects?,To ensure that the involved data types are exactly restored after completing the roundtrip and to decrease the size of the serialization string through compression.
95,95,userguide_serialization_chunks_chunk_2,10,"# Serialization

BayBE is shipped with a sophisticated serialization engine that allows to unstructure
its objects into basic types and seamlessly reassemble them afterward.
This enables a variety of advanced workflows, such as:

* Persisting objects for later use
* Transmission and processing outside the Python ecosystem
* Interaction with APIs and databases
* Writing √¢¬Ä¬úconfiguration√¢¬Ä¬ù files

Some of these workflows are demonstrated in the sections below.

## JSON (de-)serialization

Most BayBE objects can be conveniently serialized into an equivalent JSON
representation by calling their
`to_json` method.
The obtained JSON string can then be deserialized via the
`from_json` method
of the corresponding class, which yields an √¢¬Ä¬úequivalent copy√¢¬Ä¬ù of the original object.

For example:

```python
from baybe.parameters import CategoricalParameter

parameter = CategoricalParameter(name=""Setting"", values=[""low"", ""high""])
json_string = parameter.to_json()
reconstructed = CategoricalParameter.from_json(json_string)
assert parameter == reconstructed
```

This form of roundtrip serialization can be used, for instance, to persist objects
for long-term storage, but it also provides an easy way to √¢¬Ä¬úmove√¢¬Ä¬ù existing objects
between Python sessions by executing the deserializing step in a different context
than the serialization step.",Does BayBE offer serialization?,BayBE is shipped with a sophisticated serialization engine that allows to unstructured its objects into basic types and seamlessly reassemble them afterward. ,How can BayBE objects be serialized into JSON format?,By calling the `to_json` method on the object.
96,96,userguide_serialization_chunks_chunk_3,Tia,"# Serialization
## Deserialization from configuration strings

The workflow described [above](#json-serialization) most naturally applies to
situations where we start inside the Python ecosystem and want to make an object
leave the running session.
However, in many cases, we would like to kickstart the process from the other end and
rather specify a BayBE object **outside** Python for use in a later computation.
Common examples are when we wish to interact with an API or simply want to persist
a certain BayBE component in the form of a √¢¬Ä¬úconfiguration√¢¬Ä¬ù file.

The following sections give an overview of the flexibilities that are offered for this
task. Of course, the underlying concepts can be mixed and matched arbitrarily.# Serialization
## Deserialization from configuration strings
### Basic string assembly

Writing a configuration for a certain BayBE object in form of a serialization string is
easy:

1. Select your desired object class
2. Identify the arguments expected by one of its constructors (see also [here](#alternative-constructors))
3. Pack them into a JSON string that mirrors the constructor signature

Let√¢¬Ä¬ôs have a more detailed look, for instance, at the serialization string from
the [above example](#json-serialization), this time assuming we wanted to assemble
the string manually.
For this purpose, we have a peek at the signature of the `__init__` method of
`CategoricalParameter`
and notice that it has two required arguments, `name` and `values`.
We specify these accordingly as separate fields in the JSON string:

```python
from baybe.parameters import CategoricalParameter

parameter_json = """"""
{
    ""name"": ""Setting"",
    ""values"": [""low"", ""high""]
}
""""""
via_json = CategoricalParameter.from_json(parameter_json)
via_init = CategoricalParameter(name=""Setting"", values=[""low"", ""high""])

assert via_json == via_init
```",I want to use a parameter for an API call later. Is it possible to create a JSON string directly?,"Yes, you can manually write the configuration as a JSON string that matches the expected constructor parameters of the object. Here's an example for a CategoricalParameter: from baybe.parameters import CategoricalParameter

parameter_json = """"""
{
    ""name"": ""Setting"",
    ""values"": [""low"", ""high""]
}
""""""

# Deserialize from JSON
param = CategoricalParameter.from_json(parameter_json) This method is useful if you're storing configuration in a file or receiving it from an external system (like an API). Just make sure the JSON matches the expected structure for the object.",What are the two required arguments for the `__init__` method of `CategoricalParameter`?,`name` and `values`
97,97,userguide_serialization_chunks_chunk_5,3,"# Serialization
## Deserialization from configuration strings
### Using default values

Just like default values can be omitted when working in Python,
they can be omitted from the corresponding serialization string:

```python
from baybe.parameters import CategoricalParameter

p1 = CategoricalParameter(name=""Setting"", values=[""low"", ""high""])
p2 = CategoricalParameter(name=""Setting"", values=[""low"", ""high""], encoding=""OHE"")

p1_json = """"""
{
    ""name"": ""Setting"",
    ""values"": [""low"", ""high""]
}
""""""
p2_json = """"""
{
    ""name"": ""Setting"",
    ""values"": [""low"", ""high""],
    ""encoding"": ""OHE""
}
""""""

p1_via_json = CategoricalParameter.from_json(p1_json)
p2_via_json = CategoricalParameter.from_json(p2_json)

assert p1 == p1_via_json == p2 == p2_via_json
```",What happens if I omit a value from the serialization string?,"If the parameter has a default value, this one will be used. There is no information in what is going to happen if a parameter does not have a default value.",What is the encoding used for the second CategoricalParameter in the example?,OHE
98,98,userguide_serialization_chunks_chunk_6,4,"# Serialization
## Deserialization from configuration strings
### Automatic field conversion

BayBE classes apply converters to their inputs so that simpler attribute
representations can be passed.
Of course, these shortcuts can be analogously used inside a configuration string.

While the above holds generally true for all classes that have converters in place,
providing a few specific example may help to convey the concept:

* Since `Intervals` can be created *implicitly*,
  it is enough the specify their bound values directly:
  ```python
  from baybe.targets import NumericalTarget
  from baybe.utils.interval import Interval

  t1 = NumericalTarget(name=""T"", mode=""MAX"", bounds=Interval(0, 1))
  t2 = NumericalTarget(name=""T"", mode=""MAX"", bounds=(0, 1))
  t3 = NumericalTarget.from_json('{""name"": ""T"", ""mode"": ""MAX"", ""bounds"": [0, 1]}')

  assert t1 == t2 == t3
  ```
* Conversion to enums happens automatically whenever needed;
  therefore, providing a raw string instead is sufficient:
  ```python
  from baybe.targets import NumericalTarget, TargetMode

  t1 = NumericalTarget(name=""T"", mode=TargetMode.MAX)
  t2 = NumericalTarget(name=""T"", mode=""MAX"")
  t3 = NumericalTarget.from_json('{""name"": ""T"", ""mode"": ""MAX""}')

  assert t1 == t2 == t3
  ```",No,,How can `Intervals` be created using `NumericalTarget` in BayBE classes?,"`Intervals` can be created by specifying their bound values directly, such as `bounds=Interval(0, 1)` or `bounds=(0, 1)`."
99,99,userguide_serialization_chunks_chunk_7,Tia,"# Serialization
## Deserialization from configuration strings
### The type field

Due to the leading design philosophy behind BayBE to provide its users easy access
to a broad range of tools, you typically have the choice between several modelling
alternatives when building your objects.
For example, when describing the degrees of freedom of your experimental campaign,
you can chose from several different [parameter types](parameters.md).

While this offers great flexibility, it comes with a challenge for deserialization
because you cannot know a priori which concrete object subclass is contained
in an incoming serialization string on the receiving end.
Instead, you oftentimes need to be able to process the incoming string dynamically.

For example, consider the following string, which perfectly mirrors the signatures of
both
`CategoricalParameter` and
`TaskParameter`:

```python
parameter_json = """"""
{
    ""name"": ""Setting"",
    ""values"": [""low"", ""high""]
}
""""""
```

Unless you are aware of the specific purpose for which the string was created,
calling one of the classes√¢¬Ä¬ô constructors directly is impossible because you
simply do not know which one to chose.
A similar situation arises with [nested objects](#nested-objects) because resorting to
an explicit constructor call of a hand-selected subclass is only possible at the
highest level of the hierarchy, whereas the inner object types would remain unspecified.

The problem can be easily circumvented using an explicit subclass resolution
mechanism, i.e., by tagging the respective subclass in an additional `type` field that
holds the class√¢¬Ä¬ô name.
This allows to deserialize the object from the corresponding base class instead
(i.e., `Parameter` class in the example below),
mirroring the flexibility of specifying subtypes to your configuration file:

```python
from baybe.parameters.base import Parameter
from baybe.parameters import CategoricalParameter, TaskParameter

categorical_parameter = CategoricalParameter(name=""Setting"", values=[""low"", ""high""])
categorical_parameter_json = """"""
{
    ""type"": ""CategoricalParameter"",
    ""name"": ""Setting"",
    ""values"": [""low"", ""high""]
}
""""""
# NOTE: we can use `Parameter.from_json` instead of `CategoricalParameter.from_json`:
categorical_parameter_reconstructed = Parameter.from_json(categorical_parameter_json)
assert categorical_parameter == categorical_parameter_reconstructed

task_parameter = TaskParameter(name=""Setting"", values=[""low"", ""high""])
task_parameter_json = """"""
{
    ""type"": ""TaskParameter"",
    ""name"": ""Setting"",
    ""values"": [""low"", ""high""]
}
""""""
# NOTE: we can use `Parameter.from_json` instead of `TaskParameter.from_json`:
task_parameter_reconstructed = Parameter.from_json(task_parameter_json)
assert task_parameter == task_parameter_reconstructed
```

#### NOTE
When serializing an object that belongs to a class hierarchy, BayBE automatically
injects the `type` field into the serialization string to enable frictionless deserialization
at a later stage.","When deserializing nested objects with different object types, how do you make sure they are deserialized to the correct object subclasses?","The problem can be easily circumvented using an explicit subclass resolution mechanism, i.e., by tagging the respective subclass in an additional type field that holds the class' name. This allows to deserialize the object from the corresponding base class instead (i.e., {class}Parameter <baybe.parameters.base.Parameter> class in the example below), mirroring the flexibility of specifying subtypes to your configuration file: from baybe.parameters.base import Parameter
from baybe.parameters import CategoricalParameter, TaskParameter

categorical_parameter = CategoricalParameter(name=""Setting"", values=[""low"", ""high""])
categorical_parameter_json = """"""
{
    ""type"": ""CategoricalParameter"",
    ""name"": ""Setting"",
    ""values"": [""low"", ""high""]
}
""""""
# NOTE: we can use `Parameter.from_json` instead of `CategoricalParameter.from_json`:
categorical_parameter_reconstructed = Parameter.from_json(categorical_parameter_json)
assert categorical_parameter == categorical_parameter_reconstructed

task_parameter = TaskParameter(name=""Setting"", values=[""low"", ""high""])
task_parameter_json = """"""
{
    ""type"": ""TaskParameter"",
    ""name"": ""Setting"",
    ""values"": [""low"", ""high""]
}
""""""
# NOTE: we can use `Parameter.from_json` instead of `TaskParameter.from_json`:
task_parameter_reconstructed = Parameter.from_json(task_parameter_json)
assert task_parameter == task_parameter_reconstructed  
#### NOTE
When serializing an object that belongs to a class hierarchy, BayBE automatically
injects the `type` field into the serialization string to enable frictionless deserialization
at a later stage.",What field is added to the serialization string in BayBE to facilitate deserialization?,The `type` field.
100,100,userguide_serialization_chunks_chunk_8,8,"# Serialization
## Deserialization from configuration strings
### Using abbreviations

Classes that have an `abbreviation` class variable defined can be conveniently
deserialized using the corresponding abbreviation string:

```python
from baybe.acquisition.base import AcquisitionFunction

acqf1 = AcquisitionFunction.from_json('{""type"": ""UpperConfidenceBound""}')
acqf2 = AcquisitionFunction.from_json('{""type"": ""UCB""}')

assert acqf1 == acqf2
```

<a id=""nested-objects""></a>",,,"What does the abbreviation ""UCB"" stand for in the context of deserialization?",UpperConfidenceBound
101,101,userguide_serialization_chunks_chunk_9,9,"# Serialization
## Deserialization from configuration strings
### Nesting objects

BayBE objects typically appear as part of a larger object hierarchy.
For instance, a
`SearchSpace` can hold one or several
`Parameters`, just like an
`Objective` can hold one or several
`Targets`.
This hierarchical structure can be directly replicated in the serialization string:

```python
from baybe.objectives import DesirabilityObjective
from baybe.targets import NumericalTarget

objective = DesirabilityObjective(
    targets=[
        NumericalTarget(name=""T1"", mode=""MAX"", bounds=(-1, 1)),
        NumericalTarget(name=""T2"", mode=""MIN"", bounds=(0, 1)),
    ],
    weights=[0.1, 0.9],
    scalarizer=""MEAN"",
)

objective_json = """"""
{
    ""targets"": [
        {
            ""type"": ""NumericalTarget"",
            ""name"": ""T1"",
            ""mode"": ""MAX"",
            ""bounds"": [-1.0, 1.0]
        },
        {
            ""type"": ""NumericalTarget"",
            ""name"": ""T2"",
            ""mode"": ""MIN"",
            ""bounds"": [0.0, 1.0]
        }
    ],
    ""weights"": [0.1, 0.9],
    ""scalarizer"": ""MEAN""
}
""""""

assert objective == DesirabilityObjective.from_json(objective_json)
```

<a id=""alternative-constructors""></a>",How do I encode targets in BayBE? How do I set different weights for targets? I have multiple targets; how do I format my input objective?,,What is the type of the first target in the DesirabilityObjective example?,NumericalTarget
102,102,userguide_simulation_chunks_chunk_2,4,"# Simulation
BayBE offers multiple functionalities to √¢¬Ä¬úsimulate√¢¬Ä¬ù experimental campaigns with a given lookup mechanism. This user guide briefly introduces how to use the methods available in our [simulation subpackage]().

For a wide variety of applications of this functionality, we refer to the corresponding [examples]().

## Terminology: What do we mean by √¢¬Ä¬úSimulation√¢¬Ä¬ù?

The term √¢¬Ä¬úsimulation√¢¬Ä¬ù can have two slightly different interpretations, depending on the applied context.

1. It can refer to √¢¬Ä¬úbacktesting√¢¬Ä¬ù a particular experimental campaign on a fixed finite dataset.
   Thus, √¢¬Ä¬úsimulation√¢¬Ä¬ù means investigating what experimental trajectory we would have observed if we had used different setups or recommenders and restricted the possible parameter configurations to those contained in the dataset.
2. It can refer to the simulation of an *actual* DOE loop, i.e., recommending experiments and retrieving the corresponding measurements, where the loop closure is realized in the form of a callable (black-box) function that can be queried during the optimization to provide target values. Such a callable could for instance be a simple analytical function or a numerical solver of a set of differential equations that describe a physical system.",Is there a difference in how different types of simulation are handled by bayBE?,"No, there is not.","What are the two interpretations of ""simulation"" mentioned in the user guide?","The two interpretations are ""backtesting"" a particular experimental campaign on a fixed finite dataset and simulating an actual DOE loop with callable functions for optimization."
103,103,userguide_simulation_chunks_chunk_3,Tia,"# Simulation
## The Lookup Mechanism

BayBE√¢¬Ä¬ôs simulation package enables a wide range of use cases and can even be used for √¢¬Ä¬úoracle predictions√¢¬Ä¬ù.
This is made possible through the flexible use of lookup mechanisms, which act as the loop-closing element of an optimization loop.

Lookups can be provided in a variety of ways, by using fixed data sets, analytical functions, or any other form of black-box callable.
In all cases, their role is the same: to retrieve target values for parameter configurations suggested by the recommendation engine.# Simulation
## The Lookup Mechanism
### Using a `Callable`

Using a `Callable` is the most general way to provide :class: tip
If you already have a lookup callable available in an array-based format (for instance,
if your lookup values are generated using third-party code that works with array inputs
and outputs), you can effortlessly convert this callable into the required
dataframe-based format by applying our
{func}`~baybe.utils.dataframe.arrays_to_dataframes` decorator. 

For example, the above lookup can be equivalently created as follows:
```python
import numpy as np

from baybe.utils.dataframe import arrays_to_dataframes


@arrays_to_dataframes([""p1""], [""t1""])
def lookup(array: np.ndarray) -> np.ndarray:
    """"""The same lookup function in array logic.""""""
    return array**2
```a lookup mechanism.
Any `Callable` is a suitable lookup as long as it acce:class: tip
If you already have a lookup callable available in an array-based format (for instance,
if your lookup values are generated using third-party code that works with array inputs
and outputs), you can effortlessly convert this callable into the required
dataframe-based format by applying our
{func}`~baybe.utils.dataframe.arrays_to_dataframes` decorator. 

For example, the above lookup can be equivalently created as follows:
```python
import numpy as np

from baybe.utils.dataframe import arrays_to_dataframes


@arrays_to_dataframes([""p1""], [""t1""])
def lookup(array: np.ndarray) -> np.ndarray:
    """"""The same lookup function in array logic.""""""
    return array**2
```pts a dataframe containing parameter configurations and returns the corresponding target values.
More specifically:

- The input is expected to be a dataframe whose column names contain the parameter names and whose rows represent valid parameter configurations.
- The returned output must be a dataframe whose column names contain the target names and whose rows represent valid target values.
- The indices of the input and output dataframes must match.

An example might look like this:

```python
import pandas as pd

from baybe.parameters import NumericalContinuousParameter
from baybe.searchspace import SearchSpace
from baybe.targets import NumericalTarget

searchspace = SearchSpace.from_product(
    [
        NumericalContinuousParameter(""p1"", [0, 1]),
        NumericalContinuousParameter(""p2"", [-1, 1]),
    ]
)
objective = NumericalTarget(""t1"", ""MAX"").to_objective()


def lookup(df: pd.DataFrame) -> pd.DataFrame:
    """"""Map parameter configurations to target values.""""""
    return pd.DataFrame({""t1"": df[""p1""] ** 2}, index=df.index)


lookup(searchspace.continuous.sample_uniform(10))
```","If I have data in array format, can I use it as a lookup function in the simulation?",":class: tip
If you already have a lookup callable available in an array-based format (for instance,
if your lookup values are generated using third-party code that works with array inputs
and outputs), you can effortlessly convert this callable into the required
dataframe-based format by applying our
{func}`~baybe.utils.dataframe.arrays_to_dataframes` decorator. 

For example, the above lookup can be equivalently created as follows:
```python
import numpy as np

from baybe.utils.dataframe import arrays_to_dataframes


@arrays_to_dataframes([""p1""], [""t1""])
def lookup(array: np.ndarray) -> np.ndarray:
    """"""The same lookup function in array logic.""""""
    return array**2
```",What decorator is used to convert a lookup callable into a dataframe-based format in BayBE's simulation package?,The `arrays_to_dataframes` decorator.
104,104,userguide_simulation_chunks_chunk_5,3,"# Simulation
## The Lookup Mechanism
### Using a Dataframe

When dealing with discrete search spaces, it is also possible to provide the lookup values in a tabular representation using a dataframe.
To be a valid lookup, the dataframe must have columns corresponding to all parameters and targets in the modeled domain.

An example might look as follows:

```python
import pandas as pd

from baybe.parameters import NumericalDiscreteParameter
from baybe.searchspace import SearchSpace
from baybe.targets import NumericalTarget

searchspace = SearchSpace.from_product(
    [
        NumericalDiscreteParameter(""p1"", [0, 1, 2, 3]),
        NumericalDiscreteParameter(""p2"", [1, 10, 100, 1000]),
    ]
)
objective = NumericalTarget(""t"", ""MAX"").to_objective()

lookup = pd.DataFrame.from_records(
    [
        {""p1"": 0, ""p2"": 100, ""t"": 23},
        {""p1"": 2, ""p2"": 10, ""t"": 5},
        {""p1"": 3, ""p2"": 1000, ""t"": 56},
    ]
)
```tip
Ideally, all possible parameter combinations should be measured and represented in the dataframe to ensure that a backtesting simulation produces a realistic assessment of performance.
However, this is an unrealistic assumption for most applications because search spaces are oftentimes exceedingly large.
As a consequence, it may well be the case that a provided dataframe contains the measurements of only some parameter configurations while the majority of combinations is not present (like in the example above).
To address this issue, BayBE provides various methods for managing these ¬ìmissing¬î targets,
which can be configured using the {paramref}`~baybe.simulation.lookup.look_up_targets.impute_mode`
keyword of the respective simulation function.",No,,What must the dataframe have to be a valid lookup in a simulation?,The dataframe must have columns corresponding to all parameters and targets in the modeled domain.
105,105,userguide_simulation_chunks_chunk_6,7,"# Simulation
## The Lookup Mechanism
### Using `None`

When testing code, it can sometimes be helpful to have an √¢¬Ä¬úarbitrary√¢¬Ä¬ù lookup mechanism available without having to craft a custom one.
An example of when this is useful is when evaluating the actual lookup is too expensive and results in too long turnaround times (for instance, when the lookup is implemented by running complex code such as a computer simulation).
In these situations, using `None` as lookup can save valuable development time, which invokes the `add_fake_measurements()` utility behind the scenes to generate random target values for any given domain.",,,What utility is invoked when using `None` as a lookup mechanism in testing code?,`add_fake_measurements()`
106,106,userguide_simulation_chunks_chunk_7,8,"# Simulation
## Simulating a Single Experiment

The function [`simulate_experiment`]() is the most basic form of simulation.
It runs a single execution of a DoE loop for either a specific number of iteration or until the search space is fully observed.

For using this function, it is necessary to provide a [`campaign`](). Although technically not necessary, we advise to also always provide a lookup mechanisms since fake results will be produced if none is provided. It is possible to specify several additional parameters like the batch size, initial data or the number of DoE iterations that should be performed

```python
results = simulate_experiment(
    # Necessary
    campaign=campaign,
    # Technically optional but should always be set
    lookup=lookup,
    # Optional
    batch_size=batch_size,
    n_doe_iterations=n_doe_iterations,
    initial_data=initial_data,
    random_seed=random_seed,
    impute_mode=impute_mode,
    noise_percent=noise_percent,
)
```

This function returns a dataframe that contains the results. For details on the columns of this dataframe as well as the dataframes returned by the other functions discussed here, we refer to the documentation of the subpackage [here]().",,,What does the `simulate_experiment` function return?,A dataframe that contains the results.
107,107,userguide_simulation_chunks_chunk_8,9,"# Simulation
## Simulating Multiple Scenarios

The function [`simulate_scenarios`]() allows to specify multiple simulation settings at once.
Instead of a single campaign, this function expects a dictionary of campaigns, mapping scenario identifiers to `Campaign` objects.
In addition to the keyword arguments available for `simulate_experiment`, this function has two different keywords available:

1. `n_mc_iterations`: This can be used to perform multiple Monte Carlo runs with a single call. Multiple Monte Carlo runs are always advised to average out the effect of random effects such as the initial starting data.
2. `initial_data`: This can be used to provide a list of dataframe, where each dataframe is then used as initial data for an independent run. That is, the function performs one optimization loop per dataframe in this list.

Note that these two keywords are mutually exclusive.

```python
lookup = ...  # some reasonable lookup, e.g. a Callable
campaign1 = Campaign(...)
campaign2 = Campaign(...)
scenarios = {""Campaign 1"": campaign1, ""Campaign 2"": campaign2}

results = simulate_scenarios(
    scenarios=scenarios,
    lookup=lookup,
    batch_size=batch_size,
    n_doe_iterations=n_doe_iterations,
    n_mc_iterations=n_mc_iterations,
)
```","How do I simulate multiple scenarios? Iím interested in running multiple campaigns, can you show me how to do that?",,What are the two additional keywords available for the `simulate_scenarios` function?,`n_mc_iterations` and `initial_data`.
108,108,userguide_simulation_chunks_chunk_9,10,"# Simulation
## Simulating Transfer Learning

The function [`simulate_transfer_learning`]() partitions the search space into its tasks and simulates each task with the training data from the remaining tasks.

#### NOTE
Currently, this only supports discrete search spaces. See [`simulate_transfer_learning`]() for the reasons.

```python
task_param = TaskParameter(
    name=""Cell Line"",
    values=[""Liver Cell"", ""Brain Cell"", ""Skin Cell""],
)
# Define searchspace using a task parameter
searchspace = SearchSpace.from_product(parameters=[param1, param2, task_param])

# Create a suitable campaign
campaign = Campaign(searchspace=searchspace, objective=objective)

# Create a lookup dataframe. Note that this needs to have a column labeled ""Function""
# with values ""F1"" and ""F2""
lookup = DataFrame(...)

results = simulate_transfer_learning(
    campaign=campaign,
    lookup=lookup,
    batch_size=BATCH_SIZE,
    n_doe_iterations=N_DOE_ITERATIONS,
    n_mc_iterations=N_MC_ITERATIONS,
)
```",Can I use the `simulate_transfer_learning` function for continuous search spaces?,"No, only discrete spaces are supported currently",What does the function `simulate_transfer_learning` do?,It partitions the search space into its tasks and simulates each task with the training data from the remaining tasks.
109,109,userguide_surrogates_chunks_chunk_2,7,"# Surrogates

Surrogate models are used to model and estimate the unknown objective function of the
DoE campaign. BayBE offers a diverse array of surrogate models, while also allowing for
the utilization of custom models. All surrogate models are based upon the general
[`Surrogate`]() class. Some models even support transfer
learning, as indicated by the `supports_transfer_learning` attribute.

## Available Models

BayBE provides a comprehensive selection of surrogate models, empowering you to choose
the most suitable option for your specific needs. The following surrogate models are
available within BayBE:

* [`GaussianProcessSurrogate`]()
* [`BayesianLinearSurrogate`]()
* [`MeanPredictionSurrogate`]()
* [`NGBoostSurrogate`]()
* [`RandomForestSurrogate`]()

# Surrogates
## Multi-Output Modeling

Depending on the use case at hand, it may be necessary to model multiple output
variables simultaneously. However, not all surrogate types natively provide (joint)
predictive distributions for more than one variable, as indicated by their
`supports_multi_output` attribute.

In multi-output contexts, it may therefore be necessary to assemble several
single-output surrogates into a composite model to build a joint predictive model from
independent components for each output. BayBE provides two convenient mechanisms to
achieve this, both built upon the
`CompositeSurrogate` class:",,,What are the available surrogate models provided by BayBE?,"GaussianProcessSurrogate, BayesianLinearSurrogate, MeanPredictionSurrogate, NGBoostSurrogate, RandomForestSurrogate."
110,110,userguide_surrogates_chunks_chunk_4,4,"# Surrogates
## Multi-Output Modeling
### Surrogate Replication

The simplest way to construct a multi-output surrogate is to replicate a given
single-output model architecture for each of the existing output dimensions.

To replicate a given surrogate, you can either call its
`replicate()` method or use the
[`CompositeSurrogate.from_replication()`]()
convenience constructor:

```python
from baybe.surrogates import CompositeSurrogate, GaussianProcessSurrogate

composite_a = GaussianProcessSurrogate().replicate()
composite_b = CompositeSurrogate.from_replication(GaussianProcessSurrogate())

assert composite_a == composite_b
```

However, there are very few cases where such an explicit conversion is required. Because
using a single-output surrogate model in a multi-output context would trivially fail, and
because BayBE cares deeply about its users√¢¬Ä¬ô lives, it automatically performs this conversion
for you behind the scenes:

<a id=""auto-replication""></a>:class: important

When using a single-output surrogate model in a multi-output context, BayBE
automatically replicates the surrogate on the fly.

The consequence of the above is that you can use the same model object regardless
of the modeling context and its multi-output capabilities.

There is *one* notable exception where an explicit replication may still make
sense: if you want to bypass the existing multi-output mechanics of a surrogate that is
inherently multi-output compatible.",Can I overwrite the auto-replication method to implement my own surrogate?,,How can you replicate a single-output surrogate model in a multi-output context using BayBE?,You can call its `replicate()` method or use the `CompositeSurrogate.from_replication()` constructor.
111,111,userguide_surrogates_chunks_chunk_5,3,"# Surrogates
## Multi-Output Modeling
### Composite Surrogates

An alternative to surrogate replication is to manually assemble your
`CompositeSurrogate`. This can be useful if you want
to

* use the same model architecture but with different settings for each output or
* use different architectures for the outputs to begin with.

```python
from baybe.surrogates import (
    CompositeSurrogate,
    GaussianProcessSurrogate,
    RandomForestSurrogate,
)

surrogate = CompositeSurrogate(
    {
        ""target_a"": GaussianProcessSurrogate(),
        ""target_b"": RandomForestSurrogate(),
    }
)
```

A noticeable difference to the replication approach is that manual assembly requires
the exact set of target variables to be known at the time the object is created.",No,,What is the purpose of manually assembling a CompositeSurrogate?,It allows the use of the same model architecture with different settings for each output or different architectures for the outputs.
112,112,userguide_surrogates_chunks_chunk_6,8,"# Surrogates
## Extracting the Model for Advanced Study

In principle, the surrogate model does not need to be a persistent object during
Bayesian optimization since each iteration performs a new fit anyway. However, for
advanced study, such as investigating the posterior predictions, acquisition functions
or feature importance, it can be useful to directly extract the current surrogate model.

For this, BayBE provides the `get_surrogate` method, which is available for the
[`Campaign`]() or for
[recommenders]().
Below an example of how to utilize this in conjunction with the popular SHAP package:

```python
# Assuming we already have a campaign created and measurements added
data = campaign.measurements[[p.name for p in campaign.parameters]]
model = lambda x: campaign.get_surrogate().posterior(x).mean

# Apply SHAP
explainer = shap.Explainer(model, data)
shap_values = explainer(data)
shap.plots.bar(shap_values)
``` :class: note
Currently, ``get_surrogate`` always returns the surrogate model with respect to the
transformed target(s) / objective. This means that if you are using a
``SingleTargetObjective`` with a transformed target or a ``DesirabilityObjective``, the
model's output will correspond to the transformed quantities and not the original
untransformed target(s). If you are using the model for subsequent analysis this should
be kept in mind.",,,What method does BayBE provide to extract the current surrogate model during Bayesian optimization?,The `get_surrogate` method.
113,113,userguide_surrogates_chunks_chunk_7,9,"# Surrogates
## Using Custom Models

BayBE goes one step further by allowing you to incorporate custom models based on the
ONNX architecture. Note however that these cannot be retrained. For a detailed
explanation on using custom models, refer to the comprehensive examples provided in the
corresponding [example folder]().",Is there support for surrogates? Could you tell me about custom model support?,,Can custom models based on the ONNX architecture be retrained in BayBE?,"No, custom models cannot be retrained in BayBE."
114,114,userguide_targets_chunks_chunk_2,4,"# Targets
Targets play a crucial role as the connection between observables measured in an
experiment and the machine learning core behind BayBE.
In general, it is expected that you create one [`Target`]()
object for each of your observables.
The way BayBE treats multiple targets is then controlled via the
[`Objective`](objectives.md).

## NumericalTarget

Besides the `name`, a [`NumericalTarget`]()
has the following attributes:

* **The optimization** `mode`: Specifies whether we want to minimize/maximize
  the target or whether we want to match a specific value.
* **Bounds**: Defines `bounds` that constrain the range of target values.
* **A** `transformation` **function**: When bounds are provided, this is
  used to map target values into the [0, 1] interval.

","I have a numerical target that ranges from ñinf to +inf, do I need to scale it?","If bounds are provided, provide a transformation function to map target values into the [0,1] interval",What attributes does a NumericalTarget have in BayBE?,"A NumericalTarget has the optimization mode, bounds, and a transformation function."
115,115,userguide_targets_chunks_chunk_3,7,"# Targets
## NumericalTarget
### MIN and MAX mode

Here are two examples for simple maximization and minimization targets:

```python
from baybe.targets import NumericalTarget, TargetMode, TargetTransformation

max_target = NumericalTarget(
    name=""Target_1"",
    mode=TargetMode.MAX,  # can also be provided as string ""MAX""
)

min_target = NumericalTarget(
    name=""Target_2"",
    mode=""MIN"",  # can also be provided as TargetMode.MIN
    bounds=(0, 100),  # optional
    transformation=TargetTransformation.LINEAR,  # optional, will be applied if bounds are not None
)
```# Targets
## Limitations

#### IMPORTANT
`NumericalTarget` enables many use cases due to the real-valued nature of most
measurements. But it can also be used to model categorical targets if they are ordinal.
For example: If your experimental outcome is a categorical ranking into √¢¬Ä¬úbad√¢¬Ä¬ù,
√¢¬Ä¬úmediocre√¢¬Ä¬ù and √¢¬Ä¬úgood√¢¬Ä¬ù, you could use a `NumericalTarget` with bounds (1, 3), where the
categories correspond to values 1, 2 and 3 respectively.
If your target category is not ordinal, the transformation into a numerical target is
not straightforward, which is a current limitation of BayBE.
We are looking into adding more target options in the future.",,,What are the possible modes for a NumericalTarget in BayBE?,MAX and MIN.
116,116,userguide_targets_chunks_chunk_4,10,"# Targets
## NumericalTarget
### MATCH mode

If you want to match a desired value, the `TargetMode.MATCH` mode is the right choice.
In this mode, `bounds` are required and different transformations compared to `MIN`
and `MAX` modes are allowed.

Assume we want to instruct BayBE to match a value of 50 in a target.
We simply need to choose the bounds so that the midpoint is the desired value.
The spread of the bounds interval defines how fast the acceptability of a measurement
falls off away from the match value, also depending on the choice of `transformation`.

In the example below, `match_targetA` will treat all values < 45 and > 55 as
equally bad, while `match_targetB` is more forgiving in that it chooses a bell curve
transformation instead of a triangular one, and also uses a wider interval of bounds.
Both targets are configured such that the midpoint of `bounds` (in this case 50)
becomes the optimal value:

```python
from baybe.targets import NumericalTarget, TargetMode, TargetTransformation

match_targetA = NumericalTarget(
    name=""Target_3A"",
    mode=TargetMode.MATCH,
    bounds=(45, 55),  # mandatory in MATCH mode
    transformation=TargetTransformation.TRIANGULAR,  # optional, applied if bounds are not None
)
match_targetB = NumericalTarget(
    name=""Target_3B"",
    mode=""MATCH"",
    bounds=(0, 100),  # mandatory in MATCH mode
    transformation=""BELL"",  # can also be provided as TargetTransformation.BELL
)
```

Targets are used in nearly all [examples]().",What is the keyword that I need to use when using a specific target mode?,The keyword is `mode`.,What is the optimal value for the bounds in MATCH mode for `match_targetA`?,50
117,117,userguide_transfer_learning_chunks_chunk_1,9,"# Transfer Learning

BayBE offers the possibility to mix data from multiple, *similar but not identical*
campaigns in order to accelerate optimization √¢¬Ä¬ì a procedure called **transfer learning**.
This feature is automatically enabled when using a
[Gaussian process surrogate model]()
in combination with a [`TaskParameter`](). :class: note
In the scientific community, the term **transfer learning** is used in many
different ways.
Within BayBE, it refers to combining data from multiple campaigns that are from similar
contexts, which we also refer as **tasks**.
Depending on the field, this might also be known as **contextual learning**.",Does BayBE support transfer learning? Does BayBE support contextual learning? Can I mix data from multiple sources in BayBE?,,What is the term used in BayBE for the procedure that combines data from multiple similar campaigns to accelerate optimization?,Transfer learning
118,118,userguide_transfer_learning_chunks_chunk_2,Tia,"
## Unlocking Data Treasures Through Transfer Learning

A straightforward approach to combining data from different campaigns is to quantify
the differences between their contexts via one or few explicitly measured parameters
and then constraining these parameters in the active campaign to
the relevant context.

Examples where this is possible:

* **Optimization of a chemical reaction at different temperatures:**<br />
  \\\\
  Data obtained from a chemical reaction optimized at a certain temperature can be used
  in a new campaign, where the same reaction needs to be optimized again at a different
  temperature.
* **Optimization of a simulation involving a particle size:**<br />
  \\\\
  Data obtained at a smaller particle size can be utilized when starting a new
  optimization for a larger particle size or vice versa.

In these examples, the temperature and the particle size take the
role of *aligning* the individual measurement campaigns along their corresponding
context dimension. That is, the context is static *within* each campaign
(i.e., each campaign is executed at its fixed context parameter value) but the
parameter establishes an explicit relationship between the data gathered *across*
campaigns. Transfer of knowledge from one campaign to another can thus simply happen
through the existing mechanisms of a surrogate model by feeding the context
parameter as an additional regular input to the model.

Unfortunately, there are many situations where it can be difficult to quantify the
differences between the campaigns via explicit context parameters in the first place.
This might be the case if the parameters distinguishing the contexts

1. have not been recorded and cannot be measured anymore,
2. are too many and explicitly modelling them is out of question or
3. are simply unknown.

Examples for situations where explicit quantification of the context can be difficult:

* **Cell culture media optimization for different cell types:**<br />
  \\\\
  Cell types differ among many possible descriptors, and it is not known a priori
  which ones are relevant to a newly started campaign.
* **Optimization in industrial black-box contexts:**<br />
  \\\\
  When materials (such as cell lines or complex substances) stem from customers,
  they can come uncharacterized.
* **Transfer of a complicated process to another location:**<br />
  \\\\
  The transferred machinery will likely require a new calibration/optimization, which
  could benefit from the other location√¢¬Ä¬ôs data. However, is not necessarily clear what
  parameters differentiate the location context.

**Transfer learning** in BayBE offers a solution for situations such as the latter,
because it abstracts each context change between campaigns into a single dimension
encoded by a [`TaskParameter`]().
Over the course of an ongoing campaign, the relationship between current campaign data
and data from previous campaigns can then be *learned* instead of requiring hard-coded
context parameters, effectively enabling you to utilize your previous data through
an additional machine learning model component.
In many situations, this can unlock data treasures coming from similar but not identical
campaigns accumulated over many years.:class: important
Because of the need to *learn* the relationship between tasks, transfer learning is
not a magic method for zero-shot learning.
For effective information transfer, it will always need data from the ongoing campaign
to understand how other campaigns' data are related.
Otherwise, it can only build upon general patterns/trends identified in the previous
campaigns, without knowing if these patterns actually reoccur in the new campaign.
(**Note:** This can still help to jump-start the new campaign since the most influential
parameter configurations from old campaigns will then drive the initial exploration.)
Overall, if correlated task data are provided, the optimization of new campaigns
can experience a dramatic speedup.:class: warning
Because of the ability to learn the task relationships, it might be tempting to add
arbitrary data to a transfer learning enabled campaigns. We caution against this, as
uncorrelated data can actually decrease the performance of the optimization. Even a
simple preliminary correlation filter to find suitable contexts can already increase
robustness.","Can I use only old transfer-learning data in my campaign, without new experiment results?","Not entirely. For effective information transfer, it will always need data from the ongoing campaign
to understand how other campaigns' data are related.
Otherwise, it can only build upon general patterns/trends identified in the previous
campaigns, without knowing if these patterns actually reoccur in the new campaign.
(**Note:** This can still help to jump-start the new campaign since the most influential
parameter configurations from old campaigns will then drive the initial exploration.)
Overall, if correlated task data are provided, the optimization of new campaigns
can experience a dramatic speedup.",What is a key advantage of using transfer learning in BayBE for optimization campaigns?,"It enables the utilization of previous data through an additional machine learning model component, allowing for effective information transfer without requiring hard-coded context parameters."
119,119,userguide_transfer_learning_chunks_chunk_3,7,"# Transfer Learning
## The Role of the TaskParameter

The [`TaskParameter`]() is used to √¢¬Ä¬úmark√¢¬Ä¬ù the context of individual experiments and thus
to √¢¬Ä¬úalign√¢¬Ä¬ù different campaigns along their context dimension.
The set of all possible contexts is provided upon the initialization of a
[`TaskParameter`]() by providing them as `values`.
In the following example, the context might be one of several reactors in which
a chemical experiments can be conducted.

```python
from baybe.parameters import TaskParameter

TaskParameter(name=""Reactor"", values=[""ReactorA"", ""ReactorB"", ""ReactorC""])
```

If not specified further, a campaign using the [`TaskParameter`]() as specified above
would now make recommendations for all possible values of the parameter. Using the
`active_values` argument upon initialization, this behavior can be changed such that
the `campaign` only makes recommendations for the corresponding values.

The following example models a situation where experimentation data from three
different reactors are available, but new experiments should only be conducted in
`ReactorC`.

```python
from baybe.parameters import TaskParameter

TaskParameter(
    name=""Reactor"",
    values=[""ReactorA"", ""ReactorB"", ""ReactorC""],
    active_values=[""ReactorC""],
)
```

The same pattern can be easily applied to other scenarios such as changing substrates
(while screening the same reaction conditions) or formulating mixtures for different cell lines:

```python
TaskParameter(
    name=""Substrate"",
    values=[""3,5-dimethylisoxazole"", ""benzo[d]isoxazole"", ""5-methylisoxazole""],
    active_values=[""3,5-dimethylisoxazole""],
)
TaskParameter(
    name=""Cell_Line"",
    values=[""Liver cell"", ""Heart cell"", ""Hamster brain cell""],
    active_values=[""Liver cell""],
)
```",,,What is the purpose of the `TaskParameter` in transfer learning experiments?,The `TaskParameter` is used to mark the context of individual experiments and align different campaigns along their context dimension.
120,120,userguide_utils_chunks_chunk_2,Tia,"# Utilities
BayBE comes with a set of useful functions that can make your life easier in certain
scenarios.

## Search Space Memory Estimation

In search spaces that have discrete parts, the memory needed to store the respective
data can become excessively large as the number of points grows with the amount of
possible combinations arising form all discrete parameter values.

The [`SearchSpace.estimate_product_space_size`]()
and [`SubspaceDiscrete.estimate_product_space_size`]()
utilities allow estimating the memory needed to represent the discrete subspace.
They return a [`MemorySize`]() object that
contains some relevant estimates:

```python
import numpy as np

from baybe.parameters import NumericalDiscreteParameter
from baybe.searchspace import SearchSpace

# This creates 10 parameters with 20 values each.
# The resulting space would have 20^10 entries, requiring around 745 TB of memory for
# both experimental and computational representation of the search space.
parameters = [
    NumericalDiscreteParameter(name=f""p{k + 1}"", values=np.linspace(0, 100, 20))
    for k in range(10)
]

# Estimate the required memory for such a space
mem_estimate = SearchSpace.estimate_product_space_size(parameters)

# Print quantities of interest
print(""Experimental Representation"")
print(f""Estimated size: {mem_estimate.exp_rep_human_readable}"")
print(f""Estimated size in Bytes: {mem_estimate.exp_rep_bytes}"")
print(f""Expected data frame shape: {mem_estimate.exp_rep_shape}"")

print(""Computational Representation"")
print(f""Estimated size: {mem_estimate.comp_rep_human_readable}"")
print(f""Estimated size in Bytes: {mem_estimate.comp_rep_bytes}"")
print(f""Expected data frame shape: {mem_estimate.comp_rep_shape}"")
```:class: warning
{meth}`~baybe.searchspace.core.SearchSpace.estimate_product_space_size`
currently does not include the influence of potential constraints in your search space
as it is generally very hard to incorporate the effect of arbitrary constraints without
actually building the entire space. Hence, you should always **treat the number you get
as upper bound** of required memory. This can still be useful ¬ñ for instance if your
estimate already is several Exabytes, it is unlikely that most computers would be able
to handle the result even if there are constraints present.:class: warning
{meth}`~baybe.searchspace.core.SearchSpace.estimate_product_space_size`
only estimates the memory required to handle the search space. **It does not estimate
the memory required during optimization**, which can be of a similar magnitude, but
generally depends on additional factors.:class: info
Continuous parameters do not influence the size of the discrete search space part as 
they do not contribute to the combinatorial configurations like discrete parameters.
Hence, they are ignored by the utility.:class: tip
If you run into issues creating large search spaces, as for instance in mixture
use cases, you should consider resorting to more specialized ways of creation by
invoking alternative search space constructors like 
{meth}`~baybe.searchspace.discrete.SubspaceDiscrete.from_dataframe`
or 
{meth}`~baybe.searchspace.discrete.SubspaceDiscrete.from_simplex`.
Instead of creating a product space first and then filtering it down
according to constraints, they offer a more direct and thus efficient path to the 
desired result, typically requiring substantially less memory. 
For example, {meth}`~baybe.searchspace.discrete.SubspaceDiscrete.from_simplex` 
includes the mixture constraint already *during* the product creation. 
In addition, BayBE can also be installed with its optional `polars` dependency 
(`pip install baybe[polars]`) that activates efficient machinery for constraint handling.",Can I estimate the search space memory after applying my constraints?,"
{meth}`~baybe.searchspace.core.SearchSpace.estimate_product_space_size`
currently does not include the influence of potential constraints in your search space
as it is generally very hard to incorporate the effect of arbitrary constraints without
actually building the entire space. Hence, you should always **treat the number you get
as upper bound** of required memory. This can still be useful ¬ñ for instance if your
estimate already is several Exabytes, it is unlikely that most computers would be able
to handle the result even if there are constraints present.","What is the estimated memory requirement for a search space created with 10 parameters, each having 20 values?",Approximately 745 TB of memory.
121,121,userguide_utils_chunks_chunk_3,4,"# Utilities
## Reproducibility

In some scenarios, for instance when testing your code setup, it can be useful to fix
the random seeds for all relevant engines to generate reproducible results. BayBE offers
the [`set_random_seed`]() utility for this purpose:

```python
from baybe.utils.random import set_random_seed

# Set the global random seed for all relevant engines
set_random_seed(1337)

# Assuming we have a prepared campaign
campaign.recommend(5)
```

Setting the global random seed can be undesirable if there are other packages in your
setup that might unintentionally be influenced by this. For this, BayBE offers
[`temporary_seed`]():

```python
from baybe.utils.random import temporary_seed

# Set the random seed for all relevant engines temporarily within the context
with temporary_seed(1337):
    campaign.recommend(5)
```","Does the temporary seed also affect tools like numpy, which require their own seed usually?",Unclear,How can you set the global random seed in BayBE for reproducible results?,You can set the global random seed in BayBE using the `set_random_seed(1337)` function.
122,122,userguide_utils_chunks_chunk_4,3,"# Utilities
## Adding Fake Target Measurements and Parameter Noise

When creating test scripts, it is often useful to try the recommendation loop for a few
iterations. However, this requires some arbitrary target measurements to be set. Instead
of coming up with a custom logic every time, you can use the
[`add_fake_measurements`]() utility to add fake target
measurements and the [`add_parameter_noise`]()
utility to add artificial parameter noise:

```python
from baybe.utils.dataframe import add_fake_measurements, add_parameter_noise

# Get recommendations
recommendations = campaign.recommend(5)

# Add fake target measurements and artificial parameter noise to the recommendations.
# The utilities modify the dataframes inplace.
measurements = recommendations.copy()
add_fake_measurements(measurements, campaign.targets)
add_parameter_noise(measurements, campaign.parameters)

# Now continue the loop, e.g. by adding the measurements...
```",How can I efficiently test my code during development without having actual target values?,"You can use the `add_fake_measurements` function to add artificial target measurements. Furthermore, the function `add_parameter_noise` alloes adding artificial parameter noise.",What utility is used to add fake target measurements in test scripts?,`add_fake_measurements`
123,15,index_chunks_chunk_14,10,"# BayBE √¢¬Ä¬î A Bayesian Back End for Design of Experiments
## √∞¬ü¬ì¬° Telemetry

BayBE collects anonymous usage statistics **only** for employees of Merck KGaA,
Darmstadt, Germany and/or its affiliates. The recording of metrics is turned off for
all other users and is impossible due to a VPN block. In any case, the usage statistics
do **not** involve logging of recorded measurements, targets/parameters or their names
or any project information that would allow for reconstruction of details. The user and
host machine names are anonymized with via truncated hashing.

- You can verify the above statements by studying the open-source code in the
  `telemetry` module.
- You can always deactivate all telemetry by setting the environment variable
  `BAYBE_TELEMETRY_ENABLED` to `false` or `off`. For details please consult
  [this page](https://emdgroup.github.io/baybe/stable/userguide/envvars.html#telemetry).
- If you want to be absolutely sure, you can uninstall internet related packages such
  as `opentelemetry*` or its secondary dependencies from the environment. Due to the
  inability of specifying opt-out dependencies, these are installed by default, but the
  package works without them.","For whom does BayBE collect usage statistics?
","
BayBE only collects usage statistics for employees of Merck KGaA, Darmstadt, Germany.
",Who does BayBE collect anonymous usage statistics from?,"Employees of Merck KGaA, Darmstadt, Germany and/or its affiliates."
124,15,index_chunks_chunk_14,10,"# BayBE √¢¬Ä¬î A Bayesian Back End for Design of Experiments
## √∞¬ü¬ì¬° Telemetry

BayBE collects anonymous usage statistics **only** for employees of Merck KGaA,
Darmstadt, Germany and/or its affiliates. The recording of metrics is turned off for
all other users and is impossible due to a VPN block. In any case, the usage statistics
do **not** involve logging of recorded measurements, targets/parameters or their names
or any project information that would allow for reconstruction of details. The user and
host machine names are anonymized with via truncated hashing.

- You can verify the above statements by studying the open-source code in the
  `telemetry` module.
- You can always deactivate all telemetry by setting the environment variable
  `BAYBE_TELEMETRY_ENABLED` to `false` or `off`. For details please consult
  [this page](https://emdgroup.github.io/baybe/stable/userguide/envvars.html#telemetry).
- If you want to be absolutely sure, you can uninstall internet related packages such
  as `opentelemetry*` or its secondary dependencies from the environment. Due to the
  inability of specifying opt-out dependencies, these are installed by default, but the
  package works without them.", Is there any way to disable the collection of usage statistics?,Yes. Telemetry in general can be deactivated by setting the environment variable `BAYBE_TELEMETRY_ENABLED` to `false` or `off`.,Who does BayBE collect anonymous usage statistics from?,"Employees of Merck KGaA, Darmstadt, Germany and/or its affiliates."
125,20,index_chunks_chunk_7,10,"# BayBE √¢¬Ä¬î A Bayesian Back End for Design of Experiments
## √¢¬ö¬° Quick Start
### The Optimization Loop

We can now construct a campaign object that brings all pieces of the puzzle together:

```python
from baybe import Campaign

campaign = Campaign(searchspace, objective, recommender)
```

With this object at hand, we can start our experimentation cycle.
In particular:

* We can ask BayBE to `recommend` new experiments.
* We can `add_measurements` for certain experimental settings to the campaign√¢¬Ä¬ôs
  database.

Note that these two steps can be performed in any order.
In particular, available measurements can be submitted at any time and also several
times before querying the next recommendations.

```python
df = campaign.recommend(batch_size=3)
print(df)
```

```none
   Granularity  Pressure[bar]    Solvent
15      medium            1.0  Solvent D
10      coarse           10.0  Solvent C
29        fine            5.0  Solvent B
```

Note that the specific recommendations will depend on both the data
already fed to the campaign and the random number generator seed that is used.

After having conducted the corresponding experiments, we can add our measured
targets to the table and feed it back to the campaign:

```python
df[""Yield""] = [79.8, 54.1, 59.4]
campaign.add_measurements(df)
```

With the newly arrived data, BayBE can produce a refined design for the next iteration.
This loop would typically continue until a desired target value has been achieved in
the experiment.","
How can I add measurements to the campaignís database?","
You can add measurements to the campaignís database using the `add_measurements` method.",What function is used to recommend new experiments in BayBE?,`recommend`
126,95,userguide_serialization_chunks_chunk_2,10,"# Serialization

BayBE is shipped with a sophisticated serialization engine that allows to unstructure
its objects into basic types and seamlessly reassemble them afterward.
This enables a variety of advanced workflows, such as:

* Persisting objects for later use
* Transmission and processing outside the Python ecosystem
* Interaction with APIs and databases
* Writing √¢¬Ä¬úconfiguration√¢¬Ä¬ù files

Some of these workflows are demonstrated in the sections below.

## JSON (de-)serialization

Most BayBE objects can be conveniently serialized into an equivalent JSON
representation by calling their
`to_json` method.
The obtained JSON string can then be deserialized via the
`from_json` method
of the corresponding class, which yields an √¢¬Ä¬úequivalent copy√¢¬Ä¬ù of the original object.

For example:

```python
from baybe.parameters import CategoricalParameter

parameter = CategoricalParameter(name=""Setting"", values=[""low"", ""high""])
json_string = parameter.to_json()
reconstructed = CategoricalParameter.from_json(json_string)
assert parameter == reconstructed
```

This form of roundtrip serialization can be used, for instance, to persist objects
for long-term storage, but it also provides an easy way to √¢¬Ä¬úmove√¢¬Ä¬ù existing objects
between Python sessions by executing the deserializing step in a different context
than the serialization step.",Can I transform BayBE objects into a different format?,Most BayBE objects can be conveniently serialized into an equivalent JSON representation.,How can BayBE objects be serialized into JSON format?,By calling the `to_json` method on the object.
